WEBVTT

1
00:00:02.500 --> 00:00:07.169
today I'd like to talk about NGO which

2
00:00:07.370 --> 00:00:08.790
is interesting especially interesting

3
00:00:08.990 --> 00:00:10.649
for us in this course because course NGO

4
00:00:10.849 --> 00:00:12.509
is the language at the labs you're all

5
00:00:12.708 --> 00:00:14.250
going to do the labs in and so I want to

6
00:00:14.449 --> 00:00:16.890
focus today particularly on some of the

7
00:00:17.089 --> 00:00:19.080
machinery that sort of most useful in

8
00:00:19.280 --> 00:00:22.740
the labs and in most particular to

9
00:00:22.940 --> 00:00:25.970
distributed programming um first of all

10
00:00:26.170 --> 00:00:29.400
you know it's worth asking why we use go

11
00:00:29.600 --> 00:00:31.980
in this class in fact we could have used

12
00:00:32.179 --> 00:00:33.689
any one of a number of other system

13
00:00:33.890 --> 00:00:35.698
style languages plenty languages like

14
00:00:35.899 --> 00:00:38.009
Java or C sharp or even Python that

15
00:00:38.210 --> 00:00:40.529
provide the kind of facilities we need

16
00:00:40.729 --> 00:00:42.658
and indeed we used to use C++ in this

17
00:00:42.859 --> 00:00:46.878
class and it worked out fine it'll go

18
00:00:47.079 --> 00:00:48.809
indeed like many other languages

19
00:00:49.009 --> 00:00:50.518
provides a bunch of features which are

20
00:00:50.719 --> 00:00:51.448
particularly convenient

21
00:00:51.649 --> 00:00:53.208
that's good support for threads and

22
00:00:53.408 --> 00:00:56.458
locking and synchronization between

23
00:00:56.658 --> 00:00:59.038
threads which we use a lot it is a

24
00:00:59.238 --> 00:01:01.588
convenient remote procedure call package

25
00:01:01.789 --> 00:01:04.679
which doesn't sound like much but it

26
00:01:04.879 --> 00:01:06.179
actually turns out to be a significant

27
00:01:06.379 --> 00:01:09.750
constraint from in languages like C++

28
00:01:09.950 --> 00:01:11.009
for example it's actually a bit hard to

29
00:01:11.209 --> 00:01:13.378
find a convenient easy to use remote

30
00:01:13.578 --> 00:01:14.730
procedure call package and of course we

31
00:01:14.930 --> 00:01:16.369
use it all the time in this course or

32
00:01:16.569 --> 00:01:18.209
programs and different machines to talk

33
00:01:18.409 --> 00:01:22.409
to each other unlike C++ go is type safe

34
00:01:22.609 --> 00:01:24.899
and memory safe that is it's pretty hard

35
00:01:25.099 --> 00:01:27.418
to write a program that due to a bug

36
00:01:27.618 --> 00:01:28.980
scribbles over some random piece of

37
00:01:29.180 --> 00:01:31.140
memory and then causes the program to do

38
00:01:31.340 --> 00:01:34.588
mysterious things and that just

39
00:01:34.789 --> 00:01:36.119
eliminates a big class of bugs similarly

40
00:01:36.319 --> 00:01:39.480
it's garbage collected which means you

41
00:01:39.680 --> 00:01:41.668
never in danger of priam the same memory

42
00:01:41.868 --> 00:01:44.308
twice or free memory that's still in use

43
00:01:44.509 --> 00:01:46.140
or something the garbage vector just

44
00:01:46.340 --> 00:01:48.658
frees things when they stop being used

45
00:01:48.858 --> 00:01:51.719
and one thing it's maybe not obvious

46
00:01:51.920 --> 00:01:54.628
until you played around with just this

47
00:01:54.828 --> 00:01:56.518
kind of programming before but the

48
00:01:56.718 --> 00:01:58.439
combination of threads and garbage

49
00:01:58.640 --> 00:02:01.679
collection is particularly important one

50
00:02:01.879 --> 00:02:03.000
of the things that goes wrong in a non

51
00:02:03.200 --> 00:02:05.908
garbage collected language like C++ if

52
00:02:06.108 --> 00:02:08.699
you use threads is that it's always a

53
00:02:08.899 --> 00:02:10.490
bit of a puzzle and requires a bunch of

54
00:02:10.689 --> 00:02:13.230
bookkeeping to figure out when the last

55
00:02:13.430 --> 00:02:13.990
thread

56
00:02:14.189 --> 00:02:15.460
that's using a shared object has

57
00:02:15.659 --> 00:02:17.140
finished using that object because only

58
00:02:17.340 --> 00:02:19.330
then can you free the object as you end

59
00:02:19.530 --> 00:02:20.710
up writing quite a bit of coat it's like

60
00:02:20.909 --> 00:02:22.420
manually the programmer it's about a

61
00:02:22.620 --> 00:02:24.280
bunch of code to manually you know do

62
00:02:24.479 --> 00:02:26.380
reference counting or something in order

63
00:02:26.580 --> 00:02:28.270
to figure out you know when the last

64
00:02:28.469 --> 00:02:29.830
thread stopped using an object and

65
00:02:30.030 --> 00:02:32.260
that's just a pain and that problem

66
00:02:32.460 --> 00:02:34.510
completely goes away if you use garbage

67
00:02:34.710 --> 00:02:36.360
collection like we haven't go

68
00:02:36.560 --> 00:02:39.189
and finally the language is simple much

69
00:02:39.389 --> 00:02:41.260
simpler than C++ one of the problems

70
00:02:41.460 --> 00:02:44.439
with using C++ is that often if you made

71
00:02:44.639 --> 00:02:47.050
an error you know maybe even just a typo

72
00:02:47.250 --> 00:02:51.219
the the error message you get back from

73
00:02:51.419 --> 00:02:53.530
the compiler is so complicated that in

74
00:02:53.729 --> 00:02:55.960
C++ it's usually not worth trying to

75
00:02:56.159 --> 00:02:57.310
figure out what the error message meant

76
00:02:57.509 --> 00:02:59.320
and I find it's always just much quicker

77
00:02:59.520 --> 00:03:01.270
to go look at the line number and try to

78
00:03:01.469 --> 00:03:02.469
guess what the error must have been

79
00:03:02.669 --> 00:03:03.969
because the language is far too

80
00:03:04.169 --> 00:03:04.600
complicated

81
00:03:04.800 --> 00:03:06.939
whereas go is you know probably doesn't

82
00:03:07.139 --> 00:03:09.510
have a lot of people's favorite features

83
00:03:09.710 --> 00:03:11.380
but it's relatively straightforward

84
00:03:11.580 --> 00:03:14.740
language okay so at this point you're

85
00:03:14.939 --> 00:03:17.050
both on the tutorial if you're looking

86
00:03:17.250 --> 00:03:19.090
for sort of you know what to look at

87
00:03:19.289 --> 00:03:21.430
next to learn about the language a good

88
00:03:21.629 --> 00:03:22.990
place to look is the document titled

89
00:03:23.189 --> 00:03:25.390
effective go which you know you can find

90
00:03:25.590 --> 00:03:30.189
by searching the web all right the first

91
00:03:30.389 --> 00:03:32.910
thing I want to talk about is threads

92
00:03:33.110 --> 00:03:35.740
the reason why we care a lot about

93
00:03:35.939 --> 00:03:38.800
threads in this course is that threads

94
00:03:39.000 --> 00:03:41.259
are the sort of main tool we're going to

95
00:03:41.459 --> 00:03:44.170
be using to manage concurrency in

96
00:03:44.370 --> 00:03:47.140
programs and concurrency is a particular

97
00:03:47.340 --> 00:03:49.719
interest in distributed programming

98
00:03:49.919 --> 00:03:52.240
because it's often the case that one

99
00:03:52.439 --> 00:03:53.620
program actually needs to talk to a

100
00:03:53.819 --> 00:03:55.689
bunch of other computers you know client

101
00:03:55.889 --> 00:03:58.030
may talk to many servers or a server may

102
00:03:58.229 --> 00:04:00.100
be serving requests at the same time on

103
00:04:00.300 --> 00:04:02.230
behalf of many different clients and so

104
00:04:02.430 --> 00:04:04.630
we need a way to say oh you know I'm my

105
00:04:04.830 --> 00:04:05.830
program really has seven different

106
00:04:06.030 --> 00:04:07.210
things going on because it's talking to

107
00:04:07.409 --> 00:04:09.910
seven different clients and I want a

108
00:04:10.110 --> 00:04:12.250
simple way to allow it to do these seven

109
00:04:12.449 --> 00:04:14.259
different things you know without too

110
00:04:14.459 --> 00:04:16.658
much complex programming I mean sort of

111
00:04:16.858 --> 00:04:19.389
thrust threads are the answer so these

112
00:04:19.589 --> 00:04:21.430
are the things that the go documentation

113
00:04:21.629 --> 00:04:24.218
calls go routines which I call threads

114
00:04:24.418 --> 00:04:26.588
they're go routines are really this same

115
00:04:26.788 --> 00:04:27.680
as what everybody else calls

116
00:04:27.879 --> 00:04:32.360
Red's so the way to think of threads is

117
00:04:32.560 --> 00:04:36.400
that you have a program of one program

118
00:04:36.600 --> 00:04:42.920
and one address space I'm gonna draw a

119
00:04:43.120 --> 00:04:45.860
box to sort of denote an address space

120
00:04:46.060 --> 00:04:48.050
and within that address space in a

121
00:04:48.250 --> 00:04:51.319
serial program without threads you just

122
00:04:51.519 --> 00:04:54.350
have one thread of execution executing

123
00:04:54.550 --> 00:04:56.840
code in that address space one program

124
00:04:57.040 --> 00:04:59.900
counter one set of registers one stack

125
00:05:00.100 --> 00:05:01.879
that are sort of describing the current

126
00:05:02.079 --> 00:05:03.980
state of the execution in a threaded

127
00:05:04.180 --> 00:05:05.960
program like a go program you could have

128
00:05:06.160 --> 00:05:08.990
multiple threads and you know I got raw

129
00:05:09.189 --> 00:05:10.670
it as multiple squiggly lines and when

130
00:05:10.870 --> 00:05:13.280
each line represents really is a

131
00:05:13.480 --> 00:05:15.920
separate if the especially if the

132
00:05:16.120 --> 00:05:17.240
threads are executing at the same time

133
00:05:17.439 --> 00:05:19.430
but a separate program counter a

134
00:05:19.629 --> 00:05:21.350
separate set of registers and a separate

135
00:05:21.550 --> 00:05:24.020
stack for each of the threads so that

136
00:05:24.220 --> 00:05:26.030
they can have a sort of their own thread

137
00:05:26.230 --> 00:05:28.129
of control and be executing each thread

138
00:05:28.329 --> 00:05:31.610
in a different part of the program and

139
00:05:31.810 --> 00:05:33.110
so hidden here is that for every stack

140
00:05:33.310 --> 00:05:35.329
now there's a syrupy thread there's a

141
00:05:35.529 --> 00:05:40.970
stack that it's executing on the stacks

142
00:05:41.170 --> 00:05:44.329
are actually in in the one address space

143
00:05:44.529 --> 00:05:46.520
of the program so even though each stack

144
00:05:46.720 --> 00:05:47.660
each thread has its own stack

145
00:05:47.860 --> 00:05:51.020
technically the they're all in the same

146
00:05:51.220 --> 00:05:52.040
address space and different threads

147
00:05:52.240 --> 00:05:53.600
could refer to each other stacks if they

148
00:05:53.800 --> 00:05:55.759
knew the right addresses although you

149
00:05:55.959 --> 00:05:58.850
typically don't do that and then go when

150
00:05:59.050 --> 00:06:01.310
you even the main program you know when

151
00:06:01.509 --> 00:06:02.689
you first start up the program and it

152
00:06:02.889 --> 00:06:04.910
runs in main that's also it's just a go

153
00:06:05.110 --> 00:06:06.290
routine and can do all the things that

154
00:06:06.490 --> 00:06:14.240
go teens can do all right so as I

155
00:06:14.439 --> 00:06:17.650
mentioned one of the big reasons is to

156
00:06:17.850 --> 00:06:21.530
allow different parts of the program to

157
00:06:21.730 --> 00:06:24.829
sort of be in its own point in in a

158
00:06:25.029 --> 00:06:27.350
different activity so I usually refer to

159
00:06:27.550 --> 00:06:31.310
that as IO concurrency for historical

160
00:06:31.509 --> 00:06:36.379
reasons and the reason I call it IO

161
00:06:36.579 --> 00:06:37.850
concurrency is that in the old days

162
00:06:38.050 --> 00:06:39.379
where this first came up is that oh you

163
00:06:39.579 --> 00:06:41.060
might have one thread that's waiting to

164
00:06:41.259 --> 00:06:41.270
read

165
00:06:41.470 --> 00:06:43.040
from the disk and while it's waiting to

166
00:06:43.240 --> 00:06:44.210
reach from the disk you'd like to have a

167
00:06:44.410 --> 00:06:46.129
second thread that maybe can compute or

168
00:06:46.329 --> 00:06:48.800
read somewhere else in the disk or send

169
00:06:49.000 --> 00:06:50.360
a message in the network and wait for

170
00:06:50.560 --> 00:06:54.290
reply so and so I open currencies one of

171
00:06:54.490 --> 00:06:57.050
the things that threads by you for us it

172
00:06:57.250 --> 00:06:59.990
would usually mean I can I open currency

173
00:07:00.189 --> 00:07:01.490
we usually mean I can have one program

174
00:07:01.689 --> 00:07:03.889
that has launched or removed procedure

175
00:07:04.089 --> 00:07:05.810
calls requests to different servers on

176
00:07:06.009 --> 00:07:07.939
the network and is waiting for many

177
00:07:08.139 --> 00:07:10.370
replies at the same time that's how

178
00:07:10.569 --> 00:07:12.980
it'll come up for us and you know the

179
00:07:13.180 --> 00:07:14.840
way you would do that with threads is

180
00:07:15.040 --> 00:07:16.910
that you would create one thread for

181
00:07:17.110 --> 00:07:18.590
each of the remote procedure calls that

182
00:07:18.790 --> 00:07:20.990
you wanted to launch that thread would

183
00:07:21.189 --> 00:07:23.329
have code that you know sent the remote

184
00:07:23.529 --> 00:07:26.180
procedure call request message and sort

185
00:07:26.379 --> 00:07:27.620
of waited at this point in the thread

186
00:07:27.819 --> 00:07:29.120
and then finally when the reply came

187
00:07:29.319 --> 00:07:31.129
back the thread would continue executing

188
00:07:31.329 --> 00:07:33.020
and using threads allows us to have

189
00:07:33.220 --> 00:07:34.790
multiple threads that all launch

190
00:07:34.990 --> 00:07:36.050
requests into the network at the same

191
00:07:36.250 --> 00:07:38.240
time they all wait or they don't have to

192
00:07:38.439 --> 00:07:40.490
do it at the same time they can you know

193
00:07:40.689 --> 00:07:41.689
execute the different parts of this

194
00:07:41.889 --> 00:07:42.889
whenever they feel like it

195
00:07:43.089 --> 00:07:45.170
so that's i/o concurrency sort of

196
00:07:45.370 --> 00:07:49.520
overlapping of the progress of different

197
00:07:49.720 --> 00:07:53.750
activities and allowing one activity is

198
00:07:53.949 --> 00:07:56.860
waiting other activities can proceed

199
00:07:57.060 --> 00:08:00.129
another big reason to use threads is

200
00:08:00.329 --> 00:08:02.540
multi-core parallelism which I'll just

201
00:08:02.740 --> 00:08:08.480
call parallelism and here the thing

202
00:08:08.680 --> 00:08:10.069
where we'd be trying to achieve with

203
00:08:10.269 --> 00:08:11.689
threads is if you have a multi-core

204
00:08:11.889 --> 00:08:13.340
machine like I'm sure all of you do in

205
00:08:13.540 --> 00:08:15.560
your laptops if you have a sort of

206
00:08:15.759 --> 00:08:17.270
compute heavy job that needs a lot of

207
00:08:17.470 --> 00:08:18.949
CPU cycles wouldn't it be nice if you

208
00:08:19.149 --> 00:08:20.860
could have one program that could use

209
00:08:21.060 --> 00:08:23.660
CPU cycles on all of the cores of the

210
00:08:23.860 --> 00:08:25.430
machine and indeed if you write a

211
00:08:25.629 --> 00:08:27.379
multi-threaded go if you launch multiple

212
00:08:27.579 --> 00:08:29.840
go routines and go and they do something

213
00:08:30.040 --> 00:08:31.370
computer intensive like sit there in a

214
00:08:31.569 --> 00:08:33.740
loop and you know compute digits of pi

215
00:08:33.940 --> 00:08:36.468
or something then up to the limit of the

216
00:08:36.668 --> 00:08:38.319
number of cores in the physical machine

217
00:08:38.519 --> 00:08:41.059
your threads will run truly in parallel

218
00:08:41.259 --> 00:08:43.490
and if you launch you know two threads

219
00:08:43.690 --> 00:08:45.549
instead of one you'll get twice as many

220
00:08:45.750 --> 00:08:48.169
you'll be able to use twice as many CPU

221
00:08:48.370 --> 00:08:50.870
cycles per second so this is very

222
00:08:51.070 --> 00:08:52.969
important to some people it's not a big

223
00:08:53.169 --> 00:08:54.539
deal on this course

224
00:08:54.740 --> 00:08:57.240
be it's rare that we'll sort of think

225
00:08:57.440 --> 00:08:59.279
specifically about this kind of

226
00:08:59.480 --> 00:09:01.439
parallelism in the real world though of

227
00:09:01.639 --> 00:09:05.189
building things like servers to form

228
00:09:05.389 --> 00:09:06.689
parts of the distributed systems it can

229
00:09:06.889 --> 00:09:09.569
sometimes be extremely important to be

230
00:09:09.769 --> 00:09:11.579
able to have the server be able to run

231
00:09:11.779 --> 00:09:13.349
threads and harness the CPU power of a

232
00:09:13.549 --> 00:09:14.939
lot of cores just because the load from

233
00:09:15.139 --> 00:09:18.539
clients can often be pretty high okay so

234
00:09:18.740 --> 00:09:22.649
parallelism is a second reason why

235
00:09:22.850 --> 00:09:25.109
threads are quite a bit interested in

236
00:09:25.309 --> 00:09:26.969
distributed systems and a third reason

237
00:09:27.169 --> 00:09:29.339
which is maybe a little bit less

238
00:09:29.539 --> 00:09:32.579
important is there's some there's times

239
00:09:32.779 --> 00:09:35.309
when you really just want to be able to

240
00:09:35.509 --> 00:09:38.429
do something in the background or you

241
00:09:38.629 --> 00:09:39.599
know there's just something you need to

242
00:09:39.799 --> 00:09:42.569
do periodically and you don't want to

243
00:09:42.769 --> 00:09:45.059
have to sort of in the main part of your

244
00:09:45.259 --> 00:09:47.219
program sort of insert checks to say

245
00:09:47.419 --> 00:09:48.990
well should I be doing this things that

246
00:09:49.190 --> 00:09:50.879
should happen every second or so you

247
00:09:51.080 --> 00:09:52.169
just like to be able to fire something

248
00:09:52.370 --> 00:09:54.179
up that every second does whatever the

249
00:09:54.379 --> 00:09:55.859
periodic thing is so there's some

250
00:09:56.059 --> 00:10:00.299
convenience reasons and an example which

251
00:10:00.500 --> 00:10:03.179
will come up for you is it's often the

252
00:10:03.379 --> 00:10:05.009
case that some you know a master server

253
00:10:05.210 --> 00:10:07.049
may want to check periodically whether

254
00:10:07.250 --> 00:10:09.149
its workers are still alive because one

255
00:10:09.350 --> 00:10:10.379
of them is died you know you want to

256
00:10:10.580 --> 00:10:11.969
launch that work on another machine like

257
00:10:12.169 --> 00:10:14.339
MapReduce might do that and one way to

258
00:10:14.539 --> 00:10:17.219
arrange sort of oh do this check every

259
00:10:17.419 --> 00:10:18.899
second every minute you know send a

260
00:10:19.100 --> 00:10:21.479
message to the worker are you alive is

261
00:10:21.679 --> 00:10:23.969
to fire off a go routine that just sits

262
00:10:24.169 --> 00:10:25.500
in a loop that sleeps for a second and

263
00:10:25.700 --> 00:10:26.789
then does the periodic thing and then

264
00:10:26.990 --> 00:10:28.500
sleeps for a second again and so in the

265
00:10:28.700 --> 00:10:31.199
labs you'll end up firing off these kind

266
00:10:31.399 --> 00:10:36.359
of threads quite a bit yes is the

267
00:10:36.559 --> 00:10:42.269
overhead worth it yes the overhead is

268
00:10:42.470 --> 00:10:44.639
really pretty small for this stuff I

269
00:10:44.840 --> 00:10:46.500
mean you know it depends on how many you

270
00:10:46.700 --> 00:10:49.949
create a million threads that he sit in

271
00:10:50.149 --> 00:10:51.839
a loop waiting for a millisecond and

272
00:10:52.039 --> 00:10:53.759
then send a network message that's

273
00:10:53.960 --> 00:10:56.129
probably a huge load on your machine but

274
00:10:56.330 --> 00:10:59.000
if you create you know ten threads that

275
00:10:59.200 --> 00:11:01.199
sleep for a second and do a little bit

276
00:11:01.399 --> 00:11:04.649
of work it's probably not a big deal at

277
00:11:04.850 --> 00:11:06.490
all and it's

278
00:11:06.690 --> 00:11:09.818
I guarantee you the programmer time you

279
00:11:10.019 --> 00:11:13.779
say by not having to sort of mush

280
00:11:13.980 --> 00:11:15.998
together they're different different

281
00:11:16.198 --> 00:11:19.118
activities into one line of code it's

282
00:11:19.318 --> 00:11:21.248
it's worth the small amount of CPU cost

283
00:11:21.448 --> 00:11:25.959
almost always still you know you will if

284
00:11:26.159 --> 00:11:27.399
you're unlucky you'll discover in the

285
00:11:27.600 --> 00:11:30.248
labs that some loop of yours is not

286
00:11:30.448 --> 00:11:32.318
sleeping long enough or are you fired

287
00:11:32.519 --> 00:11:35.529
off a bunch of these and never made them

288
00:11:35.730 --> 00:11:37.389
exit for example and they just

289
00:11:37.589 --> 00:11:41.128
accumulate so you can push it too far

290
00:11:41.328 --> 00:11:43.479
okay so these are the reasons that the

291
00:11:43.679 --> 00:11:46.209
main reasons that people like threads a

292
00:11:46.409 --> 00:11:47.529
lot and that will use threads in this

293
00:11:47.730 --> 00:11:50.169
class any other questions about threads

294
00:11:50.370 --> 00:12:01.659
in general by asynchronous program you

295
00:12:01.860 --> 00:12:03.368
mean like a single thread of control

296
00:12:03.568 --> 00:12:06.578
that keeps state about many different

297
00:12:06.778 --> 00:12:09.308
activities yeah so this is a good

298
00:12:09.509 --> 00:12:12.008
question actually there is you know what

299
00:12:12.208 --> 00:12:13.238
would happen if we didn't have threads

300
00:12:13.438 --> 00:12:14.889
or we'd for some reason we didn't want

301
00:12:15.089 --> 00:12:16.599
to use threats like how would we be able

302
00:12:16.799 --> 00:12:18.698
to write a program that could you know a

303
00:12:18.899 --> 00:12:21.008
server that could talk to many different

304
00:12:21.208 --> 00:12:23.139
clients at the same time or a client

305
00:12:23.339 --> 00:12:24.308
that could talk to him any servers right

306
00:12:24.509 --> 00:12:25.899
what what tools could be used and it

307
00:12:26.100 --> 00:12:28.868
turns out there is sort of another line

308
00:12:29.068 --> 00:12:36.219
of another kind of another major style

309
00:12:36.419 --> 00:12:37.779
of how do you structure these programs

310
00:12:37.980 --> 00:12:38.139
called

311
00:12:38.339 --> 00:12:39.818
you call the asynchronous program I

312
00:12:40.019 --> 00:12:42.328
might call it a vent driven programming

313
00:12:42.528 --> 00:12:45.698
so sort of or you could use a vent

314
00:12:45.899 --> 00:12:50.649
prevent programming and the the general

315
00:12:50.850 --> 00:12:52.508
structure of an event-driven program is

316
00:12:52.708 --> 00:12:54.219
usually that it has a single thread and

317
00:12:54.419 --> 00:12:57.179
a single loop and what that loop does is

318
00:12:57.379 --> 00:13:01.179
sits there and waits for any input or

319
00:13:01.379 --> 00:13:03.578
sort of any event that might trigger

320
00:13:03.778 --> 00:13:05.498
processing so an event might be the

321
00:13:05.698 --> 00:13:07.599
arrival of a request from a client or a

322
00:13:07.799 --> 00:13:10.688
timer going off or if you're building a

323
00:13:10.889 --> 00:13:12.428
Window System protect many Windows

324
00:13:12.629 --> 00:13:13.988
systems on your laptops I've driven

325
00:13:14.188 --> 00:13:15.818
written an event-driven style where what

326
00:13:16.019 --> 00:13:17.438
they're waiting for is like key clicks

327
00:13:17.639 --> 00:13:18.139
or Mouse move

328
00:13:18.339 --> 00:13:20.058
or something so you might have a single

329
00:13:20.259 --> 00:13:21.349
in an event-driven program it of a

330
00:13:21.549 --> 00:13:23.149
single threat of control sits an aloof

331
00:13:23.350 --> 00:13:25.068
waits for input and whenever it gets an

332
00:13:25.269 --> 00:13:26.959
input like a packet it figures out oh

333
00:13:27.159 --> 00:13:28.548
you know which client did this packet

334
00:13:28.749 --> 00:13:31.339
come from and then it'll have a table of

335
00:13:31.539 --> 00:13:34.639
sort of what the state is of whatever

336
00:13:34.839 --> 00:13:37.998
activity its managing for that client

337
00:13:38.198 --> 00:13:40.308
and it'll say oh gosh I was in the

338
00:13:40.509 --> 00:13:42.019
middle of reading such-and-such a file

339
00:13:42.220 --> 00:13:43.909
you know now it's asked me to read the

340
00:13:44.110 --> 00:13:45.649
next block I'll go and be the next block

341
00:13:45.850 --> 00:13:55.279
and return it and threats are generally

342
00:13:55.480 --> 00:13:57.048
more convenient because they allow you

343
00:13:57.249 --> 00:13:59.868
to really you know it's much easier to

344
00:14:00.068 --> 00:14:01.488
write sequential just like straight

345
00:14:01.688 --> 00:14:03.409
lines of control code that does you know

346
00:14:03.610 --> 00:14:05.448
computes sends a message waits for

347
00:14:05.649 --> 00:14:07.008
response whatever it's much easier to

348
00:14:07.208 --> 00:14:08.808
write that kind of code in a thread than

349
00:14:09.009 --> 00:14:13.308
it is to chop up whatever the activity

350
00:14:13.509 --> 00:14:16.068
is into a bunch of little pieces that

351
00:14:16.269 --> 00:14:18.889
can sort of be activated one at a time

352
00:14:19.089 --> 00:14:23.178
by one of these event-driven loops that

353
00:14:23.379 --> 00:14:28.909
said the well and so one problem with

354
00:14:29.110 --> 00:14:30.889
the scheme is that it's it's a little

355
00:14:31.089 --> 00:14:32.688
bit of a pain to program another

356
00:14:32.889 --> 00:14:34.459
potential defect is that while you get

357
00:14:34.659 --> 00:14:36.438
io concurrency from this approach you

358
00:14:36.639 --> 00:14:38.568
don't get CPU parallelism so if you're

359
00:14:38.769 --> 00:14:39.709
writing a busy server that would really

360
00:14:39.909 --> 00:14:42.529
like to keep you know 32 cores busy on a

361
00:14:42.730 --> 00:14:45.409
big server machine you know a single

362
00:14:45.610 --> 00:14:48.948
loop is you know it's it's not a very

363
00:14:49.149 --> 00:14:50.419
natural way to harness more than one

364
00:14:50.620 --> 00:14:54.828
core on the other hand the overheads of

365
00:14:55.028 --> 00:14:56.419
adventure and programming are generally

366
00:14:56.620 --> 00:14:59.058
quite a bit less than threads you know

367
00:14:59.259 --> 00:15:01.459
Ed's are pretty cheap but each one of

368
00:15:01.659 --> 00:15:05.178
these threads is sitting on a stack you

369
00:15:05.379 --> 00:15:07.128
know stack is a kilobyte or a kilobytes

370
00:15:07.328 --> 00:15:09.258
or something you know if you have 20 of

371
00:15:09.458 --> 00:15:10.758
these threads who cares if you have a

372
00:15:10.958 --> 00:15:12.769
million of these threads then it's

373
00:15:12.970 --> 00:15:13.808
starting to be a huge amount of memory

374
00:15:14.009 --> 00:15:17.568
and you know maybe the scheduling

375
00:15:17.769 --> 00:15:19.188
bookkeeping for deciding what the thread

376
00:15:19.389 --> 00:15:20.779
to run next might also start you know

377
00:15:20.980 --> 00:15:23.058
you now have list scheduling lists with

378
00:15:23.259 --> 00:15:25.698
a thousand threads in them the threads

379
00:15:25.899 --> 00:15:28.219
can start to get quite expensive so if

380
00:15:28.419 --> 00:15:30.318
you are in a position where you need to

381
00:15:30.519 --> 00:15:31.759
have a single server that sir

382
00:15:31.960 --> 00:15:33.319
you know a million clients and has to

383
00:15:33.519 --> 00:15:34.849
sort of keep a little bit of state for

384
00:15:35.049 --> 00:15:37.719
each of a million clients this could be

385
00:15:37.919 --> 00:15:39.169
expensive

386
00:15:39.370 --> 00:15:43.699
and it's easier to write a very you know

387
00:15:43.899 --> 00:15:45.859
at some expense in programmer time it's

388
00:15:46.059 --> 00:15:47.240
easier to write a really stripped-down

389
00:15:47.440 --> 00:15:50.359
efficient low overhead service in a

390
00:15:50.559 --> 00:15:51.740
venture than programming just a lot more

391
00:15:51.940 --> 00:16:15.189
work are you asking my JavaScript I

392
00:16:15.389 --> 00:16:17.839
don't know the question is whether

393
00:16:18.039 --> 00:16:20.750
JavaScript has multiple cores executing

394
00:16:20.950 --> 00:16:25.669
your does anybody know depends on the

395
00:16:25.870 --> 00:16:27.049
implementation yeah so I don't know I

396
00:16:27.250 --> 00:16:29.029
mean it's a natural thought though even

397
00:16:29.230 --> 00:16:31.370
in you know even an NGO you might well

398
00:16:31.570 --> 00:16:33.199
want to have if you knew your machine

399
00:16:33.399 --> 00:16:34.969
had eight cores if you wanted to write

400
00:16:35.169 --> 00:16:36.799
the world's most efficient whatever

401
00:16:37.000 --> 00:16:39.289
server you could fire up eight threads

402
00:16:39.490 --> 00:16:42.649
and on each of the threads run sort of

403
00:16:42.850 --> 00:16:47.149
stripped-down event-driven loop just you

404
00:16:47.350 --> 00:16:49.459
know sort of one event loop Recor and

405
00:16:49.659 --> 00:16:50.959
that you know that would be a way to get

406
00:16:51.159 --> 00:16:54.500
both parallelism and to the bio

407
00:16:54.700 --> 00:16:59.160
concurrency yes

408
00:17:05.059 --> 00:17:06.669
okay so the question is what's the

409
00:17:06.869 --> 00:17:07.750
difference between threads and processes

410
00:17:07.950 --> 00:17:10.990
so usually on a like a UNIX machine a

411
00:17:11.190 --> 00:17:14.680
process is a single program that you're

412
00:17:14.880 --> 00:17:16.450
running and a sort of single address

413
00:17:16.650 --> 00:17:18.490
space a single bunch of memory for the

414
00:17:18.690 --> 00:17:21.909
process and inside a process you might

415
00:17:22.109 --> 00:17:23.440
have multiple threads and when you ready

416
00:17:23.640 --> 00:17:25.089
to go program and you run the go program

417
00:17:25.289 --> 00:17:28.149
running the go program creates one unix

418
00:17:28.349 --> 00:17:31.690
process and one sort of memory area and

419
00:17:31.890 --> 00:17:35.680
then when your go process creates go

420
00:17:35.880 --> 00:17:37.180
routines those are so sitting inside

421
00:17:37.380 --> 00:17:40.750
that one process so I'm not sure that's

422
00:17:40.950 --> 00:17:42.789
really an answer but just historically

423
00:17:42.990 --> 00:17:45.159
the operating systems have provided like

424
00:17:45.359 --> 00:17:47.289
this big box is the process that's

425
00:17:47.490 --> 00:17:49.379
implemented by the operating system and

426
00:17:49.579 --> 00:17:51.849
the individual and some of the operating

427
00:17:52.049 --> 00:17:53.740
system does not care what happens inside

428
00:17:53.940 --> 00:17:56.349
your process what language you use none

429
00:17:56.549 --> 00:17:58.930
of the operating systems business but

430
00:17:59.130 --> 00:18:00.609
inside that process you can run lots of

431
00:18:00.809 --> 00:18:03.309
threads now you know if you run more

432
00:18:03.509 --> 00:18:05.019
than one process in your machine you

433
00:18:05.220 --> 00:18:06.430
know you run more than one program I can

434
00:18:06.630 --> 00:18:09.369
edit or compiler the operating system

435
00:18:09.569 --> 00:18:12.159
keep quite separate right you're your

436
00:18:12.359 --> 00:18:13.419
editor and your compiler each have

437
00:18:13.619 --> 00:18:15.490
memory but it's not the same memory that

438
00:18:15.690 --> 00:18:16.629
are not allowed to look at each other

439
00:18:16.829 --> 00:18:18.609
memory there's not much interaction

440
00:18:18.809 --> 00:18:19.839
between different processes so you

441
00:18:20.039 --> 00:18:22.269
redditor may have threads and your

442
00:18:22.470 --> 00:18:23.829
compiler may have threads but they're

443
00:18:24.029 --> 00:18:27.279
just in different worlds so within any

444
00:18:27.480 --> 00:18:28.990
one program the threads can share memory

445
00:18:29.190 --> 00:18:31.690
and can synchronize with channels and

446
00:18:31.890 --> 00:18:33.519
use mutexes and stuff but between

447
00:18:33.720 --> 00:18:38.039
processes there's just no no interaction

448
00:18:38.240 --> 00:18:41.109
that's just a traditional structure of

449
00:18:41.309 --> 00:18:45.139
these this kind of software

450
00:18:45.509 --> 00:18:48.509
yeah

451
00:18:53.369 --> 00:18:55.279
so the question is when a context switch

452
00:18:55.480 --> 00:18:59.190
happens does it happened for all threads

453
00:19:08.009 --> 00:19:10.220
okay so let's let's imagine you have a

454
00:19:10.420 --> 00:19:12.379
single core machine that's really only

455
00:19:12.579 --> 00:19:14.329
running and as just doing one thing at a

456
00:19:14.529 --> 00:19:19.700
time maybe the right way to think about

457
00:19:19.900 --> 00:19:21.379
it is that you're going to be you're

458
00:19:21.579 --> 00:19:22.759
running multiple processes on your

459
00:19:22.960 --> 00:19:27.319
machine the operating system will give

460
00:19:27.519 --> 00:19:30.980
the CPU sort of time slicing back and

461
00:19:31.180 --> 00:19:33.230
forth between these two programs so when

462
00:19:33.430 --> 00:19:35.750
the hardware timer ticks and the

463
00:19:35.950 --> 00:19:37.099
operating systems decides it's time to

464
00:19:37.299 --> 00:19:38.750
take away the CPU from the currently

465
00:19:38.950 --> 00:19:40.279
running process and give it to another

466
00:19:40.480 --> 00:19:44.700
process that's done at a process level

467
00:19:48.599 --> 00:19:52.129
it's complicated all right let me let me

468
00:19:52.329 --> 00:19:55.039
let me restart this these the threads

469
00:19:55.240 --> 00:19:57.529
that we use are based on threads that

470
00:19:57.730 --> 00:19:59.869
are provided by the operating system in

471
00:20:00.069 --> 00:20:01.879
the end and when the outer needs to some

472
00:20:02.079 --> 00:20:03.710
context switches its switching between

473
00:20:03.910 --> 00:20:06.319
the threads that it knows about so in a

474
00:20:06.519 --> 00:20:08.419
situation like this the operating system

475
00:20:08.619 --> 00:20:09.619
might know that there are two threads

476
00:20:09.819 --> 00:20:11.359
here in this process and three threads

477
00:20:11.559 --> 00:20:13.399
in this process and when the timer ticks

478
00:20:13.599 --> 00:20:14.990
the operating system will based on some

479
00:20:15.190 --> 00:20:16.669
scheduling algorithm pick a different

480
00:20:16.869 --> 00:20:18.529
thread to run it might be a different

481
00:20:18.730 --> 00:20:20.930
thread in this process or one of the

482
00:20:21.130 --> 00:20:22.069
threads in this process

483
00:20:22.269 --> 00:20:25.490
in addition go cleverly multiplex as

484
00:20:25.690 --> 00:20:27.579
many go routines on top of single

485
00:20:27.779 --> 00:20:29.659
operating system threads to reduce

486
00:20:29.859 --> 00:20:32.389
overhead so it's really probably a two

487
00:20:32.589 --> 00:20:34.279
stages of scheduling the operating

488
00:20:34.480 --> 00:20:37.129
system picks which big thread to run and

489
00:20:37.329 --> 00:20:39.829
then within that process go may have a

490
00:20:40.029 --> 00:20:43.289
choice of go routines to run

491
00:20:45.819 --> 00:20:53.209
all right okay so threads are convenient

492
00:20:53.409 --> 00:20:55.338
because a lot of times they allow you to

493
00:20:55.538 --> 00:20:57.348
write the code for each thread just as

494
00:20:57.548 --> 00:20:59.719
if it were a pretty ordinary sequential

495
00:20:59.919 --> 00:21:04.338
program however there are in fact some

496
00:21:04.538 --> 00:21:10.528
challenges with writing threaded code

497
00:21:15.148 --> 00:21:17.479
one is what to do about shared data one

498
00:21:17.679 --> 00:21:18.798
of the really cool things about the

499
00:21:18.999 --> 00:21:20.448
threading model is that these threads

500
00:21:20.648 --> 00:21:22.158
share the same address space they share

501
00:21:22.358 --> 00:21:24.108
memory if one thread creates an object

502
00:21:24.308 --> 00:21:26.719
in memory you can let other threads use

503
00:21:26.919 --> 00:21:28.938
it right you can have a array or

504
00:21:29.138 --> 00:21:30.288
something that all the different threads

505
00:21:30.489 --> 00:21:31.219
are reading and writing and that

506
00:21:31.419 --> 00:21:33.678
sometimes critical right if you you know

507
00:21:33.878 --> 00:21:34.879
if you're keeping some interesting state

508
00:21:35.079 --> 00:21:36.108
you know maybe you have a cache of

509
00:21:36.308 --> 00:21:38.898
things that your server your cache and

510
00:21:39.098 --> 00:21:40.639
memory when a thread is handling a

511
00:21:40.839 --> 00:21:42.108
client request it's gonna first look in

512
00:21:42.308 --> 00:21:43.608
that cache but the shared cache and each

513
00:21:43.808 --> 00:21:45.198
thread reads it and the threads may

514
00:21:45.398 --> 00:21:47.808
write the cache to update it when they

515
00:21:48.009 --> 00:21:48.979
have new information to stick in the

516
00:21:49.179 --> 00:21:51.019
cache so it's really cool you can share

517
00:21:51.220 --> 00:21:55.009
that memory but it turns out that it's

518
00:21:55.210 --> 00:21:57.769
very very easy to get bugs if you're not

519
00:21:57.970 --> 00:21:59.538
careful and you're sharing memory

520
00:21:59.739 --> 00:22:02.389
between threads so a totally classic

521
00:22:02.589 --> 00:22:05.328
example is you know supposing your

522
00:22:05.528 --> 00:22:07.428
thread so you have a global variable N

523
00:22:07.628 --> 00:22:09.469
and that's shared among the different

524
00:22:09.669 --> 00:22:11.240
threads and a thread just wants to

525
00:22:11.440 --> 00:22:17.358
increment n right but itself this is

526
00:22:17.558 --> 00:22:20.509
likely to be an invitation to bugs right

527
00:22:20.710 --> 00:22:22.038
if you don't do anything special around

528
00:22:22.239 --> 00:22:24.918
this code and the reason is that you

529
00:22:25.118 --> 00:22:27.318
know whenever you write code in a thread

530
00:22:27.519 --> 00:22:29.719
that you you know is accessing reading

531
00:22:29.919 --> 00:22:31.698
or writing data that's shared with other

532
00:22:31.898 --> 00:22:33.469
threads you know there's always the

533
00:22:33.669 --> 00:22:35.058
possibility and you got to keep in mind

534
00:22:35.259 --> 00:22:36.798
that some other thread may be looking at

535
00:22:36.999 --> 00:22:39.348
the data or modifying the data at the

536
00:22:39.548 --> 00:22:41.538
same time so the obvious problem with

537
00:22:41.739 --> 00:22:43.698
this is that maybe thread 1 is executing

538
00:22:43.898 --> 00:22:45.918
this code and thread 2 is actually in

539
00:22:46.118 --> 00:22:47.658
the same function in a different thread

540
00:22:47.858 --> 00:22:50.598
executing the very same code right and

541
00:22:50.798 --> 00:22:52.848
remember I'm imagining the N is a global

542
00:22:53.048 --> 00:22:54.168
variable so they're talking about the

543
00:22:54.368 --> 00:22:56.838
same n so what this boils down to you

544
00:22:57.038 --> 00:22:58.068
know you're not actually running this

545
00:22:58.269 --> 00:22:58.848
code you're running

546
00:22:59.048 --> 00:23:01.548
machine code the compiler produced and

547
00:23:01.749 --> 00:23:03.678
what that machine code does is it you

548
00:23:03.878 --> 00:23:06.519
know it loads X into a register

549
00:23:06.720 --> 00:23:13.009
you know adds one to the register and

550
00:23:13.210 --> 00:23:17.928
then stores that register into X with

551
00:23:18.128 --> 00:23:20.808
where X is a address of some location

552
00:23:21.009 --> 00:23:22.879
and ran so you know you can count on

553
00:23:23.079 --> 00:23:24.139
both of the threads

554
00:23:24.339 --> 00:23:25.729
they're both executing this line of code

555
00:23:25.929 --> 00:23:28.519
you know they both load the variable X

556
00:23:28.720 --> 00:23:30.889
into a register effect starts out at 0

557
00:23:31.089 --> 00:23:32.269
that means they both load at 0

558
00:23:32.470 --> 00:23:33.769
they both increment that register so

559
00:23:33.970 --> 00:23:35.418
they get one and they both store one

560
00:23:35.618 --> 00:23:37.608
back to memory and now two threads of

561
00:23:37.808 --> 00:23:39.798
incremented n and the resulting value is

562
00:23:39.999 --> 00:23:43.818
1 which well who knows what the

563
00:23:44.019 --> 00:23:45.288
programmer intended maybe that's what

564
00:23:45.489 --> 00:23:47.088
the programmer wanted but chances are

565
00:23:47.288 --> 00:23:48.948
not right chances are the programmer

566
00:23:49.148 --> 00:24:02.509
wanted to not 1 some some instructions

567
00:24:02.710 --> 00:24:04.038
are atomic so the question is a very

568
00:24:04.239 --> 00:24:09.438
good question which it's whether

569
00:24:09.638 --> 00:24:11.058
individual instructions are atomic so

570
00:24:11.259 --> 00:24:13.068
the answer is some are and some aren't

571
00:24:13.269 --> 00:24:20.358
so a store a 32-bit store is likely the

572
00:24:20.558 --> 00:24:23.240
extremely likely to be atomic in the

573
00:24:23.440 --> 00:24:25.548
sense that if 2 processors store at the

574
00:24:25.749 --> 00:24:27.759
same time to the same memory address

575
00:24:27.960 --> 00:24:30.529
32-bit values well you'll end up with is

576
00:24:30.730 --> 00:24:32.959
either the 32 bits from one processor or

577
00:24:33.159 --> 00:24:34.969
the 32 bits from the other processor but

578
00:24:35.169 --> 00:24:38.000
not a mixture other sizes it's not so

579
00:24:38.200 --> 00:24:40.250
clear like one byte stores it depends on

580
00:24:40.450 --> 00:24:41.779
the CPU you using because a one byte

581
00:24:41.980 --> 00:24:44.240
store is really almost certainly a 32

582
00:24:44.440 --> 00:24:47.719
byte load and then a modification of 8

583
00:24:47.919 --> 00:24:50.149
bits and a 32 byte store but it depends

584
00:24:50.349 --> 00:24:51.619
on the processor and more complicated

585
00:24:51.819 --> 00:24:54.408
instructions like increment your

586
00:24:54.608 --> 00:24:55.698
microprocessor may well have an

587
00:24:55.898 --> 00:24:57.558
increment instruction that can directly

588
00:24:57.759 --> 00:25:00.019
increment some memory location like

589
00:25:00.220 --> 00:25:04.038
pretty unlikely to be atomic although

590
00:25:04.239 --> 00:25:05.418
there's atomic versions of some of these

591
00:25:05.618 --> 00:25:07.690
instructions

592
00:25:07.890 --> 00:25:12.539
so there's no way all right so this is

593
00:25:12.740 --> 00:25:16.479
this is a just classic danger and it's

594
00:25:16.679 --> 00:25:20.289
usually called a race I'm gonna come up

595
00:25:20.490 --> 00:25:22.479
a lot is you're gonna do a lot of

596
00:25:22.679 --> 00:25:25.079
threaded programming with shared state

597
00:25:25.279 --> 00:25:27.549
race I think refers to as some ancient

598
00:25:27.750 --> 00:25:30.369
class of bugs involving electronic

599
00:25:30.569 --> 00:25:33.460
circuits but for us that you know the

600
00:25:33.660 --> 00:25:34.839
reason why it's called a race is because

601
00:25:35.039 --> 00:25:37.569
if one of the CPUs have started

602
00:25:37.769 --> 00:25:42.909
executing this code and the other one

603
00:25:43.109 --> 00:25:44.589
the others thread is sort of getting

604
00:25:44.789 --> 00:25:46.119
close to this code it's sort of a race

605
00:25:46.319 --> 00:25:47.889
as to whether the first processor can

606
00:25:48.089 --> 00:25:50.108
finish and get to the store before the

607
00:25:50.308 --> 00:25:53.169
second processor start status execute

608
00:25:53.369 --> 00:25:54.608
the load if the first processor actually

609
00:25:54.808 --> 00:25:57.009
manages it to do the store before the

610
00:25:57.210 --> 00:25:58.869
second processor gets to the load then

611
00:25:59.069 --> 00:26:00.549
the second processor will see the stored

612
00:26:00.750 --> 00:26:03.250
value and the second processor will load

613
00:26:03.450 --> 00:26:07.190
one and add one to it in store two

614
00:26:07.369 --> 00:26:10.000
that's how you can justify this

615
00:26:10.200 --> 00:26:13.479
terminology okay and so the way you

616
00:26:13.679 --> 00:26:15.069
solve this certainly something this

617
00:26:15.269 --> 00:26:16.690
simple is you insert locks

618
00:26:16.890 --> 00:26:19.269
you know you as a programmer you have

619
00:26:19.470 --> 00:26:23.710
some strategy in mind for locking the

620
00:26:23.910 --> 00:26:26.069
data you can say well you know this

621
00:26:26.269 --> 00:26:28.629
piece of shared data can only be used

622
00:26:28.829 --> 00:26:31.299
when such-and-such a lock is held and

623
00:26:31.500 --> 00:26:32.889
you'll see this and you may have used

624
00:26:33.089 --> 00:26:36.460
this in the tutorial the go calls locks

625
00:26:36.660 --> 00:26:39.598
mutexes so what you'll see is a mule Ock

626
00:26:39.798 --> 00:26:43.930
before a sequence of code that uses

627
00:26:44.130 --> 00:26:48.119
shared data and you unlock afterwards

628
00:26:48.319 --> 00:26:51.819
and then whichever two threads execute

629
00:26:52.019 --> 00:26:53.139
this when it to everyone is lucky enough

630
00:26:53.339 --> 00:26:56.019
to get the lock first gets to do all

631
00:26:56.220 --> 00:26:57.399
this stuff and finish before the other

632
00:26:57.599 --> 00:26:59.649
one is allowed to proceed and so you can

633
00:26:59.849 --> 00:27:02.139
think of wrapping a some code in a lock

634
00:27:02.339 --> 00:27:05.259
as making a bunch of you know remember

635
00:27:05.460 --> 00:27:06.819
this even though it's one line it's

636
00:27:07.019 --> 00:27:10.180
really three distinct operations you can

637
00:27:10.380 --> 00:27:13.469
think of a lock as causing this sort of

638
00:27:13.669 --> 00:27:15.839
multi-step code sequence to be atomic

639
00:27:16.039 --> 00:27:18.039
with respect to other people who have to

640
00:27:18.240 --> 00:27:21.319
lock yes

641
00:27:26.369 --> 00:27:30.379
should you sissy can you repeat the

642
00:27:30.579 --> 00:27:30.769
question

643
00:27:30.970 --> 00:27:36.889
oh that's a great question the question

644
00:27:37.089 --> 00:27:38.839
was how does go know which variable

645
00:27:39.039 --> 00:27:41.149
we're walking right here of course is

646
00:27:41.349 --> 00:27:42.889
only one variable but maybe we're saying

647
00:27:43.089 --> 00:27:45.710
an equals x plus y really threes few

648
00:27:45.910 --> 00:27:47.240
different variables and the answer is

649
00:27:47.440 --> 00:27:52.690
that go has no idea it's not there's no

650
00:27:52.890 --> 00:27:54.829
Association at all

651
00:27:55.029 --> 00:27:57.829
anywhere between this lock so this new

652
00:27:58.029 --> 00:28:00.440
thing is a variable which is a tight

653
00:28:00.640 --> 00:28:04.399
mutex there's just there's no

654
00:28:04.599 --> 00:28:07.430
association in the language between the

655
00:28:07.630 --> 00:28:10.519
lock and any variables the associations

656
00:28:10.720 --> 00:28:12.139
in the programmers head so as a

657
00:28:12.339 --> 00:28:14.269
programmer you need to say oh here's a

658
00:28:14.470 --> 00:28:18.470
bunch of shared data and any time you

659
00:28:18.670 --> 00:28:20.569
modify any of it you know here's a

660
00:28:20.769 --> 00:28:22.609
complex data structure say a tree or an

661
00:28:22.809 --> 00:28:24.079
expandable hash table or something

662
00:28:24.279 --> 00:28:26.359
anytime you're going to modify it and of

663
00:28:26.559 --> 00:28:27.619
course a tree is composed many many

664
00:28:27.819 --> 00:28:29.509
objects anytime you got to modify

665
00:28:29.710 --> 00:28:30.680
anything that's associated with this

666
00:28:30.880 --> 00:28:32.089
data structure you have to hold such and

667
00:28:32.289 --> 00:28:34.339
such a lock right and of course is many

668
00:28:34.539 --> 00:28:36.379
objects and instead of objects changes

669
00:28:36.579 --> 00:28:37.430
because you might allocate new tree

670
00:28:37.630 --> 00:28:39.919
nodes but it's really the programmer who

671
00:28:40.119 --> 00:28:41.779
sort of works out a strategy for

672
00:28:41.980 --> 00:28:44.509
ensuring that the data structure is used

673
00:28:44.710 --> 00:28:47.269
by only one core at a time and so it

674
00:28:47.470 --> 00:28:50.059
creates the one or maybe more locks and

675
00:28:50.259 --> 00:28:51.470
there's many many locking strategies you

676
00:28:51.670 --> 00:28:52.819
could apply to a tree you can imagine a

677
00:28:53.019 --> 00:28:57.379
tree with a lock for every tree node the

678
00:28:57.579 --> 00:28:58.579
programmer works out the strategy

679
00:28:58.779 --> 00:29:00.470
allocates the locks and keeps in the

680
00:29:00.670 --> 00:29:02.029
programmers head the relationship to the

681
00:29:02.230 --> 00:29:04.759
data but go for go it's this is this

682
00:29:04.960 --> 00:29:07.490
lock it's just like a very simple thing

683
00:29:07.690 --> 00:29:10.730
there's a lock object the first thread

684
00:29:10.930 --> 00:29:12.769
that calls lock gets the lock other

685
00:29:12.970 --> 00:29:14.569
threads have to wait until none locks

686
00:29:14.769 --> 00:29:18.539
and that's all go knows

687
00:29:18.799 --> 00:29:21.159
yeah

688
00:29:23.990 --> 00:29:26.529
does it not lock all variables that are

689
00:29:26.730 --> 00:29:28.839
part of the object go doesn't know

690
00:29:29.039 --> 00:29:30.490
anything about the relationship between

691
00:29:30.690 --> 00:29:33.519
variables and locks so when you acquire

692
00:29:33.720 --> 00:29:37.509
that lock when you have code that calls

693
00:29:37.710 --> 00:29:41.079
lock exactly what it is doing it is

694
00:29:41.279 --> 00:29:44.019
acquiring this lock and that's all this

695
00:29:44.220 --> 00:29:47.079
does and anybody else who tries to lock

696
00:29:47.279 --> 00:29:49.059
objects so somewhere else who would have

697
00:29:49.259 --> 00:29:54.970
declared you know mutex knew all right

698
00:29:55.170 --> 00:29:56.379
and this mu refers to some particular

699
00:29:56.579 --> 00:29:58.210
lock object no and there me many many

700
00:29:58.410 --> 00:30:01.149
locks right all this does is acquires

701
00:30:01.349 --> 00:30:04.419
this lock and anybody else who wants to

702
00:30:04.619 --> 00:30:05.799
acquire it has to wait until we unlock

703
00:30:06.000 --> 00:30:08.919
this lock that's totally up to us as

704
00:30:09.119 --> 00:30:11.769
programmers what we were protecting with

705
00:30:11.970 --> 00:30:33.369
that lock so the question is is it

706
00:30:33.569 --> 00:30:37.899
better to have the lock be a private the

707
00:30:38.099 --> 00:30:39.460
private business of the data structure

708
00:30:39.660 --> 00:30:42.690
like supposing it a zoning map yeah and

709
00:30:42.890 --> 00:30:44.619
you know you would hope although it's

710
00:30:44.819 --> 00:30:46.659
not true that map internally would have

711
00:30:46.859 --> 00:30:49.659
a lock protecting it and that's a

712
00:30:49.859 --> 00:30:54.039
reasonable strategy would be to have I

713
00:30:54.240 --> 00:30:56.139
mean what would be to have it if you

714
00:30:56.339 --> 00:30:58.149
define a data structure that needs to be

715
00:30:58.349 --> 00:30:59.619
locked to have the lock be sort of

716
00:30:59.819 --> 00:31:01.450
interior that have each of the data

717
00:31:01.650 --> 00:31:03.009
structures methods be responsible for

718
00:31:03.210 --> 00:31:04.659
acquiring that lock and the user the

719
00:31:04.859 --> 00:31:06.639
data structure may never know that

720
00:31:06.839 --> 00:31:09.009
that's pretty reasonable and the only

721
00:31:09.210 --> 00:31:10.629
point at which that breaks down is that

722
00:31:10.829 --> 00:31:15.730
um well it's a couple things one is if

723
00:31:15.930 --> 00:31:17.889
the programmer knew that the data was

724
00:31:18.089 --> 00:31:20.710
never shared they might be bummed that

725
00:31:20.910 --> 00:31:22.000
they were paying the lock overhead for

726
00:31:22.200 --> 00:31:23.200
something they knew didn't need to be

727
00:31:23.400 --> 00:31:25.619
locked so that's one potential problem

728
00:31:25.819 --> 00:31:30.940
the other is that if you if there's any

729
00:31:31.140 --> 00:31:32.859
inter data structure of dependencies so

730
00:31:33.059 --> 00:31:34.839
we have two data structures each with

731
00:31:35.039 --> 00:31:35.819
locks and

732
00:31:36.019 --> 00:31:38.509
and they maybe use each other then

733
00:31:38.710 --> 00:31:40.879
there's a risk of cycles and deadlocks

734
00:31:41.079 --> 00:31:44.960
right and the deadlocks can be solved

735
00:31:45.160 --> 00:31:47.399
but the usual solutions to deadlocks

736
00:31:47.599 --> 00:31:52.169
requires lifting the locks out of out of

737
00:31:52.369 --> 00:31:54.089
the implementations up into the calling

738
00:31:54.289 --> 00:31:55.799
code I will talk about that some point

739
00:31:56.000 --> 00:31:58.980
but it's not a it's a good idea to hide

740
00:31:59.180 --> 00:32:00.509
the locks but it's not always a good

741
00:32:00.710 --> 00:32:11.399
idea all right okay so one problem you

742
00:32:11.599 --> 00:32:13.859
run into with threads is these races and

743
00:32:14.059 --> 00:32:16.169
generally you solve them with locks okay

744
00:32:16.369 --> 00:32:17.819
or actually there's two big strategies

745
00:32:18.019 --> 00:32:19.230
one is you figure out some locking

746
00:32:19.430 --> 00:32:22.129
strategy for making access to the data

747
00:32:22.329 --> 00:32:24.980
single thread one thread at a time or

748
00:32:25.180 --> 00:32:28.970
yury you fix your code to not share data

749
00:32:29.170 --> 00:32:32.220
if you can do that it's that's probably

750
00:32:32.420 --> 00:32:35.339
better because it's less complex all

751
00:32:35.539 --> 00:32:38.129
right so another issue that shows up

752
00:32:38.329 --> 00:32:39.899
with leads threads is called

753
00:32:40.099 --> 00:32:44.579
coordination when we're doing locking

754
00:32:44.779 --> 00:32:46.470
the different threads involved probably

755
00:32:46.670 --> 00:32:48.329
have no idea that the other ones exist

756
00:32:48.529 --> 00:32:49.619
they just want to like be able to get

757
00:32:49.819 --> 00:32:51.450
out the data without anybody else

758
00:32:51.650 --> 00:32:53.759
interfering but there are also cases

759
00:32:53.960 --> 00:32:55.019
where you need where you do

760
00:32:55.220 --> 00:32:56.669
intentionally want different threads to

761
00:32:56.869 --> 00:32:58.169
interact I want to wait for you

762
00:32:58.369 --> 00:32:59.730
maybe you're producing some data you

763
00:32:59.930 --> 00:33:01.349
know you're a different thread than me

764
00:33:01.549 --> 00:33:02.940
you're you're producing data I'm gonna

765
00:33:03.140 --> 00:33:05.700
wait until you've generated the data

766
00:33:05.900 --> 00:33:09.779
before I read it right or you launch a

767
00:33:09.980 --> 00:33:10.980
bunch of threads to say you crawl the

768
00:33:11.180 --> 00:33:12.240
web and you want to wait for all those

769
00:33:12.440 --> 00:33:13.980
fits to finish so there's times when we

770
00:33:14.180 --> 00:33:16.769
intentionally want different to us to

771
00:33:16.970 --> 00:33:18.059
interact with each other to wait for

772
00:33:18.259 --> 00:33:18.569
each other

773
00:33:18.769 --> 00:33:23.319
and that's usually called coordination

774
00:33:23.440 --> 00:33:26.430
and there's a bunch of as you probably

775
00:33:26.630 --> 00:33:28.049
know from having done the tutorial

776
00:33:28.250 --> 00:33:31.019
there's a bunch of techniques in go for

777
00:33:31.220 --> 00:33:34.098
doing this like channels

778
00:33:34.298 --> 00:33:36.828
which are really about sending data from

779
00:33:37.028 --> 00:33:38.750
one threat to another and breeding but

780
00:33:38.950 --> 00:33:41.838
they did to be sent there's also other

781
00:33:42.038 --> 00:33:45.038
stuff that more special purpose things

782
00:33:45.239 --> 00:33:48.740
like there's a idea called condition

783
00:33:48.940 --> 00:33:51.348
variables which is great if there's some

784
00:33:51.548 --> 00:33:53.028
thread out there and you want to kick it

785
00:33:53.229 --> 00:33:54.288
period you're not sure if the other

786
00:33:54.489 --> 00:33:55.638
threads even waiting for you but if it

787
00:33:55.838 --> 00:33:57.259
is waiting for you you just like to give

788
00:33:57.459 --> 00:33:59.298
it a kick so it can well know that it

789
00:33:59.499 --> 00:34:01.308
should continue whatever it's doing and

790
00:34:01.509 --> 00:34:06.078
then there's wait group which is

791
00:34:06.278 --> 00:34:08.060
particularly good for launching a a

792
00:34:08.260 --> 00:34:10.250
known number of go routines and then

793
00:34:10.449 --> 00:34:14.269
waiting for them Dolph to finish and a

794
00:34:14.469 --> 00:34:15.859
final piece of damage that comes up with

795
00:34:16.059 --> 00:34:23.419
threads deadlock the deadlock refers to

796
00:34:23.619 --> 00:34:25.729
the general problem that you sometimes

797
00:34:25.929 --> 00:34:29.019
run into where one thread

798
00:34:29.219 --> 00:34:32.629
you know thread this thread is waiting

799
00:34:32.829 --> 00:34:35.659
for thread two to produce something so

800
00:34:35.858 --> 00:34:37.550
you know it's draw an arrow to say

801
00:34:37.750 --> 00:34:40.969
thread one is waiting for thread two you

802
00:34:41.168 --> 00:34:42.079
know for example thread one may be

803
00:34:42.278 --> 00:34:43.789
waiting for thread two to release a lock

804
00:34:43.989 --> 00:34:46.490
or to send something on the channel or

805
00:34:46.690 --> 00:34:48.079
to you know decrement something in a

806
00:34:48.278 --> 00:34:51.379
wait group however unfortunately maybe T

807
00:34:51.579 --> 00:34:55.010
two is waiting for thread thread one to

808
00:34:55.210 --> 00:34:57.700
do something and this is particularly

809
00:34:57.900 --> 00:34:59.869
common in the case of locks its thread

810
00:35:00.068 --> 00:35:01.639
one acquires lock a and thread to

811
00:35:01.838 --> 00:35:05.539
acquire lock be so thread one is

812
00:35:05.739 --> 00:35:07.490
acquired lock a throw two is required

813
00:35:07.690 --> 00:35:11.030
lot B and then next thread one needs to

814
00:35:11.230 --> 00:35:14.389
lock B also that is hold two locks which

815
00:35:14.588 --> 00:35:15.710
sometimes shows up and it just so

816
00:35:15.909 --> 00:35:17.089
happens that thread two needs to hold

817
00:35:17.289 --> 00:35:19.789
block hey that's a deadlock all right at

818
00:35:19.989 --> 00:35:21.289
least grab their first lock and then

819
00:35:21.489 --> 00:35:23.210
proceed down to where they need their

820
00:35:23.409 --> 00:35:24.320
second lock and now they're waiting for

821
00:35:24.519 --> 00:35:26.539
each other forever right neither can

822
00:35:26.739 --> 00:35:28.579
proceed neither then can release the

823
00:35:28.778 --> 00:35:33.369
lock and usually just nothing happens so

824
00:35:33.568 --> 00:35:35.990
if your program just kind of grinds to a

825
00:35:36.190 --> 00:35:37.220
halt and doesn't seem to be doing

826
00:35:37.420 --> 00:35:39.800
anything but didn't crash deadlock is

827
00:35:40.000 --> 00:35:42.960
it's one thing to check

828
00:35:43.798 --> 00:35:48.139
okay all right let's look at the web

829
00:35:48.338 --> 00:35:53.659
crawler from the tutorial as an example

830
00:35:53.858 --> 00:36:00.230
of some of this threading stuff I have a

831
00:36:00.429 --> 00:36:03.530
couple of two solutions and different

832
00:36:03.730 --> 00:36:07.430
styles are really three solutions in

833
00:36:07.630 --> 00:36:09.230
different styles to allow us to talk a

834
00:36:09.429 --> 00:36:10.579
bit about the details of some of this

835
00:36:10.778 --> 00:36:13.339
thread programming so first of all you

836
00:36:13.539 --> 00:36:15.919
all probably know web crawler its job is

837
00:36:16.119 --> 00:36:18.289
you give it the URL of a page that it

838
00:36:18.489 --> 00:36:20.269
starts at and you know many web pages

839
00:36:20.469 --> 00:36:22.909
have links to other pages so what a web

840
00:36:23.108 --> 00:36:24.649
crawler is trying to do is if that's the

841
00:36:24.849 --> 00:36:27.409
first page extract all the URLs that

842
00:36:27.608 --> 00:36:29.329
were mentioned that pages links you know

843
00:36:29.528 --> 00:36:31.849
fetch the pages they point to look at

844
00:36:32.048 --> 00:36:33.530
all those pages for the ules are all

845
00:36:33.730 --> 00:36:35.539
those but all urls that they refer to

846
00:36:35.739 --> 00:36:38.180
and keep on going until it's fetched all

847
00:36:38.380 --> 00:36:41.030
the pages in the web let's just say and

848
00:36:41.230 --> 00:36:45.289
then it should stop in addition the the

849
00:36:45.489 --> 00:36:51.950
graph of pages and URLs is cyclic that

850
00:36:52.150 --> 00:36:53.180
is if you're not careful

851
00:36:53.380 --> 00:36:55.220
um you may end up following if you don't

852
00:36:55.420 --> 00:36:56.899
remember oh I've already fetched this

853
00:36:57.099 --> 00:36:58.818
web page already you may end up

854
00:36:59.018 --> 00:37:01.250
following cycles forever and you know

855
00:37:01.449 --> 00:37:03.379
your crawler will never finish so one of

856
00:37:03.579 --> 00:37:05.359
the jobs of the crawler is to remember

857
00:37:05.559 --> 00:37:07.940
the set of pages that is already crawled

858
00:37:08.139 --> 00:37:10.579
or already even started a fetch for and

859
00:37:10.778 --> 00:37:15.619
to not start a second fetch for any page

860
00:37:15.818 --> 00:37:17.000
that it's already started fetching on

861
00:37:17.199 --> 00:37:18.649
and you can think of that as sort of

862
00:37:18.849 --> 00:37:21.559
imposing a tree structure finding a sort

863
00:37:21.759 --> 00:37:25.068
of tree shaped subset of the cyclic

864
00:37:25.268 --> 00:37:31.609
graph of actual web pages okay so we

865
00:37:31.809 --> 00:37:33.230
want to avoid cycles we want to be able

866
00:37:33.429 --> 00:37:36.859
to not fetch a page twice it also it

867
00:37:37.059 --> 00:37:38.089
turns out that it just takes a long time

868
00:37:38.289 --> 00:37:39.889
to fetch a web page but it's good

869
00:37:40.088 --> 00:37:41.960
servers are slow and because the network

870
00:37:42.159 --> 00:37:46.760
has a long speed of light latency and so

871
00:37:46.960 --> 00:37:48.470
you definitely don't want to fetch pages

872
00:37:48.670 --> 00:37:50.089
one at a time unless you want to crawl

873
00:37:50.289 --> 00:37:53.990
to take many years so it pays enormous

874
00:37:54.190 --> 00:37:55.830
lead to fetch many pages that same

875
00:37:56.030 --> 00:37:57.780
I'm up to some limit right you want to

876
00:37:57.980 --> 00:37:59.280
keep on increasing the number of pages

877
00:37:59.480 --> 00:38:01.289
you fetch in parallel until the

878
00:38:01.489 --> 00:38:02.940
throughput you're getting in pages per

879
00:38:03.139 --> 00:38:05.490
second stops increasing that is running

880
00:38:05.690 --> 00:38:07.710
increase the concurrency until you run

881
00:38:07.909 --> 00:38:11.100
out of network capacity so we want to be

882
00:38:11.300 --> 00:38:12.300
able to launch multiple fetches in

883
00:38:12.500 --> 00:38:15.780
parallel and a final challenge which is

884
00:38:15.980 --> 00:38:17.700
sometimes the hardest thing to solve is

885
00:38:17.900 --> 00:38:19.200
to know when the crawl is finished

886
00:38:19.400 --> 00:38:21.420
and once we've crawled all the pages we

887
00:38:21.619 --> 00:38:23.910
want to stop and say we're done but we

888
00:38:24.110 --> 00:38:25.170
actually need to write the code to

889
00:38:25.369 --> 00:38:26.910
realize aha

890
00:38:27.110 --> 00:38:29.640
we've crawled every single page and for

891
00:38:29.840 --> 00:38:32.280
some solutions I've tried figuring out

892
00:38:32.480 --> 00:38:33.690
when you're done has turned out to be

893
00:38:33.889 --> 00:38:38.220
the hardest part all right so my first

894
00:38:38.420 --> 00:38:40.530
crawler is this serial crawler here and

895
00:38:40.730 --> 00:38:43.200
by the way this code is available on the

896
00:38:43.400 --> 00:38:45.780
website under crawler go on the schedule

897
00:38:45.980 --> 00:38:48.300
you won't look at it this wrist calls a

898
00:38:48.500 --> 00:38:53.039
serial crawler it effectively performs a

899
00:38:53.239 --> 00:38:57.920
depth-first search into the web graph

900
00:38:58.119 --> 00:39:02.670
and there is sort of one moderately

901
00:39:02.869 --> 00:39:04.289
interesting thing about it it keeps this

902
00:39:04.489 --> 00:39:06.450
map called fetched which is basically

903
00:39:06.650 --> 00:39:08.430
using as a set in order to remember

904
00:39:08.630 --> 00:39:11.010
which pages it's crawled and that's like

905
00:39:11.210 --> 00:39:12.630
the only interesting part of this you

906
00:39:12.829 --> 00:39:16.050
give it a URL that at line 18 if it's

907
00:39:16.250 --> 00:39:17.720
already fetched the URL it just returns

908
00:39:17.920 --> 00:39:20.010
if it doesn't fetch the URL it first

909
00:39:20.210 --> 00:39:22.220
remembers that it is now fetched it

910
00:39:22.420 --> 00:39:25.860
actually gets fetches that page and

911
00:39:26.059 --> 00:39:27.450
extracts the URLs that are in the page

912
00:39:27.650 --> 00:39:29.340
with the fetcher and then iterates over

913
00:39:29.539 --> 00:39:33.230
the URLs in that page and calls itself

914
00:39:33.429 --> 00:39:35.460
for every one of those pages and it

915
00:39:35.659 --> 00:39:37.860
passes to itself the way it it really

916
00:39:38.059 --> 00:39:39.810
has just a one table there's only one

917
00:39:40.010 --> 00:39:42.870
fetched map of course because you know

918
00:39:43.070 --> 00:39:45.570
when I call recursive crawl and it

919
00:39:45.769 --> 00:39:47.130
fetches a bunch of pages after it

920
00:39:47.329 --> 00:39:49.769
returns I want to be where you know the

921
00:39:49.969 --> 00:39:52.140
outer crawl instance needs to be aware

922
00:39:52.340 --> 00:39:53.760
that certain pages are already fetched

923
00:39:53.960 --> 00:39:56.130
so we depend very much on the fetched

924
00:39:56.329 --> 00:39:58.050
map being passed between the functions

925
00:39:58.250 --> 00:40:01.769
by reference instead of by copying so it

926
00:40:01.969 --> 00:40:03.570
so under the hood what must really be

927
00:40:03.769 --> 00:40:05.130
going on here is that go is passing a

928
00:40:05.329 --> 00:40:08.280
pointer to the map object

929
00:40:08.480 --> 00:40:09.870
to each of the calls of crawl so they

930
00:40:10.070 --> 00:40:12.630
all share the pointer to the same object

931
00:40:12.829 --> 00:40:15.539
and memory rather than copying rather

932
00:40:15.739 --> 00:40:22.560
than copying than that any questions so

933
00:40:22.760 --> 00:40:23.940
this code definitely does not solve the

934
00:40:24.139 --> 00:40:25.560
problem that was posed right because it

935
00:40:25.760 --> 00:40:30.450
doesn't launch parallel parallel fetches

936
00:40:30.650 --> 00:40:33.000
now so clue we need to insert goroutines

937
00:40:33.199 --> 00:40:34.950
somewhere in this code right to get

938
00:40:35.150 --> 00:40:37.680
parallel fetches so let's suppose just

939
00:40:37.880 --> 00:40:41.280
for chuckles dad we just start with the

940
00:40:41.480 --> 00:40:51.240
most lazy thing because why so I'm gonna

941
00:40:51.440 --> 00:40:54.750
just modify the code to run the

942
00:40:54.949 --> 00:40:57.269
subsidiary crawls each in its own go

943
00:40:57.469 --> 00:41:00.269
routine actually before I do that why

944
00:41:00.469 --> 00:41:01.380
don't I run the code just to show you

945
00:41:01.579 --> 00:41:03.870
what correct output looks like so hoping

946
00:41:04.070 --> 00:41:07.470
this other window Emad run the crawler

947
00:41:07.670 --> 00:41:09.180
it actually runs all three copies of the

948
00:41:09.380 --> 00:41:10.769
crawler and they all find exactly the

949
00:41:10.969 --> 00:41:14.130
same set of webpages so this is the

950
00:41:14.329 --> 00:41:15.900
output that we're hoping to see five

951
00:41:16.099 --> 00:41:19.019
lines five different web pages are are

952
00:41:19.219 --> 00:41:20.550
fetched prints a line for each one so

953
00:41:20.750 --> 00:41:25.920
let me now run the subsidiary crawls in

954
00:41:26.119 --> 00:41:27.930
their own go routines and run that code

955
00:41:28.130 --> 00:41:35.340
so what am I going to see the hope is to

956
00:41:35.539 --> 00:41:37.680
fetch these webpages in parallel for

957
00:41:37.880 --> 00:41:42.600
higher performance so okay so you're

958
00:41:42.800 --> 00:41:44.910
voting for only seeing one URL and why

959
00:41:45.110 --> 00:41:47.680
so why is that

960
00:41:50.980 --> 00:41:55.019
yeah yes that's exactly right you know

961
00:41:55.219 --> 00:41:58.800
after the after it's not gonna wait in

962
00:41:59.000 --> 00:42:00.359
this loop at line 26 it's gonna zip

963
00:42:00.559 --> 00:42:02.250
right through that loop I was gonna

964
00:42:02.449 --> 00:42:04.649
fetch 1p when the ferry first webpage at

965
00:42:04.849 --> 00:42:06.839
line 22 and then a loop it's gonna fly

966
00:42:07.039 --> 00:42:08.190
off the girl routines and immediately

967
00:42:08.389 --> 00:42:10.019
the scroll function is gonna return and

968
00:42:10.219 --> 00:42:11.789
if it was called from main main what was

969
00:42:11.989 --> 00:42:13.589
exit almost certainly before any of the

970
00:42:13.789 --> 00:42:15.000
routines was able to do any work at all

971
00:42:15.199 --> 00:42:16.680
so we'll probably just see the first web

972
00:42:16.880 --> 00:42:19.490
page and I'm gonna do when I run it

973
00:42:19.690 --> 00:42:23.720
you'll see here under serial that only

974
00:42:23.920 --> 00:42:26.460
the one web page was found now in fact

975
00:42:26.659 --> 00:42:28.530
since this program doesn't exit after

976
00:42:28.730 --> 00:42:30.599
the serial crawler those Guru T's are

977
00:42:30.798 --> 00:42:32.068
still running and they actually print

978
00:42:32.268 --> 00:42:35.190
their output down here interleaved with

979
00:42:35.389 --> 00:42:37.619
the next crawler example but

980
00:42:37.818 --> 00:42:42.629
nevertheless the codes just adding a go

981
00:42:42.829 --> 00:42:45.629
here absolutely doesn't work so let's

982
00:42:45.829 --> 00:42:49.379
get rid of that okay so now I want to

983
00:42:49.579 --> 00:42:51.990
show you a one style of concurrent

984
00:42:52.190 --> 00:42:55.589
crawler and I'm presenting to one of

985
00:42:55.789 --> 00:42:59.550
them written with shared data shared

986
00:42:59.750 --> 00:43:02.609
objects and locks it's the first one and

987
00:43:02.809 --> 00:43:04.859
another one written without shared data

988
00:43:05.059 --> 00:43:08.789
but with passing information along

989
00:43:08.989 --> 00:43:11.159
channels in order to coordinate the

990
00:43:11.358 --> 00:43:12.720
different threads so this is the shared

991
00:43:12.920 --> 00:43:16.800
data one or this is just one of many

992
00:43:17.000 --> 00:43:18.780
ways of building a web crawler using

993
00:43:18.980 --> 00:43:22.260
shared data so this code significantly

994
00:43:22.460 --> 00:43:25.879
more complicated than a serial crawler

995
00:43:26.079 --> 00:43:30.930
it creates a thread for each fetch it

996
00:43:31.130 --> 00:43:33.539
does alright but the huge difference is

997
00:43:33.739 --> 00:43:38.190
that it does with two things one it does

998
00:43:38.389 --> 00:43:40.500
the bookkeeping required to notice when

999
00:43:40.699 --> 00:43:44.490
all of the crawls have finished and it

1000
00:43:44.690 --> 00:43:47.700
handles the shared table of which URLs

1001
00:43:47.900 --> 00:43:49.649
have been crawled correctly so this code

1002
00:43:49.849 --> 00:43:53.609
still has this table of URLs and that's

1003
00:43:53.809 --> 00:43:59.149
this F dot fetched this F dot fetch

1004
00:43:59.349 --> 00:44:05.930
map at line 43 but this this table is

1005
00:44:06.130 --> 00:44:10.460
actually shared by all of the all of the

1006
00:44:10.659 --> 00:44:11.990
crawler threads and all the collar

1007
00:44:12.190 --> 00:44:14.690
threads are making or executing inside

1008
00:44:14.889 --> 00:44:16.700
concurrent mutex and so we still have

1009
00:44:16.900 --> 00:44:18.409
this sort of tree up in current mutexes

1010
00:44:18.608 --> 00:44:20.419
that's exploring different parts of the

1011
00:44:20.619 --> 00:44:22.399
web graph but each one of them was

1012
00:44:22.599 --> 00:44:25.460
launched as a as his own go routine

1013
00:44:25.659 --> 00:44:28.519
instead of as a function call but

1014
00:44:28.719 --> 00:44:30.200
they're all sharing this table of state

1015
00:44:30.400 --> 00:44:32.659
this table of test URLs because if one

1016
00:44:32.858 --> 00:44:34.789
go routine fetches a URL we don't want

1017
00:44:34.989 --> 00:44:36.769
another girl routine to accidentally

1018
00:44:36.969 --> 00:44:40.220
fetch the same URL and as you can see

1019
00:44:40.420 --> 00:44:42.950
here line 42 and 45 I've surrounded them

1020
00:44:43.150 --> 00:44:48.050
by the new taxes that are required to to

1021
00:44:48.250 --> 00:44:50.899
prevent a race that would occur if I

1022
00:44:51.099 --> 00:44:52.700
didn't add them new Texas so the danger

1023
00:44:52.900 --> 00:44:57.530
here is that at line 43 a thread is

1024
00:44:57.730 --> 00:44:59.780
checking of URLs already been fetched so

1025
00:44:59.980 --> 00:45:02.480
two threads happen to be following the

1026
00:45:02.679 --> 00:45:06.619
same URL now two calls to concurrent

1027
00:45:06.818 --> 00:45:09.289
mutex end up looking at the same URL

1028
00:45:09.489 --> 00:45:10.940
maybe because that URL was mentioned in

1029
00:45:11.139 --> 00:45:13.730
two different web pages if we didn't

1030
00:45:13.929 --> 00:45:17.359
have the lock they'd both access the

1031
00:45:17.559 --> 00:45:18.619
math table to see if the threaded and

1032
00:45:18.818 --> 00:45:20.629
then already if the URL had been already

1033
00:45:20.829 --> 00:45:23.450
fetched and they both get false at line

1034
00:45:23.650 --> 00:45:26.869
43 they both set the URLs entering the

1035
00:45:27.068 --> 00:45:30.680
table to true at line 44 and at 47 they

1036
00:45:30.880 --> 00:45:32.180
will both see that I already was false

1037
00:45:32.380 --> 00:45:33.680
and then they both go on to patch the

1038
00:45:33.880 --> 00:45:36.830
web page so we need the lock there and

1039
00:45:37.030 --> 00:45:38.539
the way to think about it I think is

1040
00:45:38.739 --> 00:45:41.210
that we want lines 43 and 44 to be

1041
00:45:41.409 --> 00:45:43.820
atomic that is we don't want some other

1042
00:45:44.019 --> 00:45:45.710
thread to to get in and be using the

1043
00:45:45.909 --> 00:45:48.260
table between 43 and 44 we we want to

1044
00:45:48.460 --> 00:45:50.149
read the current content each thread

1045
00:45:50.349 --> 00:45:52.490
wants to read the current table contents

1046
00:45:52.690 --> 00:45:55.580
and update it without any other thread

1047
00:45:55.780 --> 00:45:57.109
interfering and so that's what the locks

1048
00:45:57.309 --> 00:46:00.950
are doing for us okay so so actually any

1049
00:46:01.150 --> 00:46:03.080
questions about the about the locking

1050
00:46:03.280 --> 00:46:05.940
strategy here

1051
00:46:07.750 --> 00:46:10.560
all right once we check the URLs entry

1052
00:46:10.760 --> 00:46:13.470
in the table alliant 51 it just crawls

1053
00:46:13.670 --> 00:46:15.120
it just fetches that page in the usual

1054
00:46:15.320 --> 00:46:18.750
way and then the other thing interesting

1055
00:46:18.949 --> 00:46:20.400
thing that's going on is the launching

1056
00:46:20.599 --> 00:46:35.250
of the threads yes so the question is

1057
00:46:35.449 --> 00:46:43.769
what's with the F dot no no the MU it is

1058
00:46:43.969 --> 00:46:46.920
okay so there's a structure to find out

1059
00:46:47.119 --> 00:46:50.130
line 36 that sort of collects together

1060
00:46:50.329 --> 00:46:53.730
all the different stuff that all the

1061
00:46:53.929 --> 00:46:55.080
different state that we need to run this

1062
00:46:55.280 --> 00:46:57.180
crawl and here it's only two objects but

1063
00:46:57.380 --> 00:46:58.620
you know it could be a lot more and

1064
00:46:58.820 --> 00:47:00.420
they're only grouped together for

1065
00:47:00.619 --> 00:47:01.830
convenience there's no other

1066
00:47:02.030 --> 00:47:05.190
significance to the fact there's no deep

1067
00:47:05.389 --> 00:47:07.289
significance the fact that mu and fetch

1068
00:47:07.489 --> 00:47:11.550
store it inside the same structure and

1069
00:47:11.750 --> 00:47:14.490
that F dot is just sort of the syntax

1070
00:47:14.690 --> 00:47:15.690
are getting out one of the elements in

1071
00:47:15.889 --> 00:47:16.980
the structure so I just happened to put

1072
00:47:17.179 --> 00:47:18.870
them you in the structure because it

1073
00:47:19.070 --> 00:47:20.880
allows me to group together all the

1074
00:47:21.079 --> 00:47:22.590
stuff related to a crawl but that

1075
00:47:22.789 --> 00:47:25.400
absolutely does not mean that go

1076
00:47:25.599 --> 00:47:28.680
associates the MU with that structure or

1077
00:47:28.880 --> 00:47:30.750
with the fetch map or anything it's just

1078
00:47:30.949 --> 00:47:33.510
a lock objects and just has a lock

1079
00:47:33.710 --> 00:47:34.890
function you can call and that's all

1080
00:47:35.090 --> 00:47:37.930
that's going on

1081
00:47:53.789 --> 00:47:58.550
so the question is how come in order to

1082
00:47:58.750 --> 00:48:00.320
pass something by reference I had to use

1083
00:48:00.519 --> 00:48:02.240
star here where it is when a in the

1084
00:48:02.440 --> 00:48:03.740
previous example when we were passing a

1085
00:48:03.940 --> 00:48:05.840
map we didn't have to use star that is

1086
00:48:06.039 --> 00:48:07.369
didn't have to pass a pointer I mean

1087
00:48:07.568 --> 00:48:08.869
that star notation you're seeing there

1088
00:48:09.068 --> 00:48:15.139
in mine 41 basically and he's saying

1089
00:48:15.338 --> 00:48:16.609
that we're passing a pointer to this

1090
00:48:16.809 --> 00:48:19.010
fetch state object and we want it to be

1091
00:48:19.210 --> 00:48:20.359
a pointer because we want there to be

1092
00:48:20.559 --> 00:48:21.800
one object in memory and all the

1093
00:48:22.000 --> 00:48:23.510
different go routines I want to use that

1094
00:48:23.710 --> 00:48:25.039
same object so they all need a pointer

1095
00:48:25.239 --> 00:48:27.800
to that same object so so we need to

1096
00:48:28.000 --> 00:48:29.210
find your own structure that's sort of

1097
00:48:29.409 --> 00:48:30.740
the syntax you use for passing a pointer

1098
00:48:30.940 --> 00:48:32.330
the reason why we didn't have to do it

1099
00:48:32.530 --> 00:48:35.720
with map is because although it's not

1100
00:48:35.920 --> 00:48:38.800
clear from the syntax a map is a pointer

1101
00:48:39.000 --> 00:48:42.379
it's just because it's built into the

1102
00:48:42.579 --> 00:48:44.869
language they don't make you put a star

1103
00:48:45.068 --> 00:48:50.330
there but what a map is is if you

1104
00:48:50.530 --> 00:48:52.220
declare a variable type map what that is

1105
00:48:52.420 --> 00:48:55.119
is a pointer to some data in the heap so

1106
00:48:55.318 --> 00:48:57.379
it was a pointer anyway and it's always

1107
00:48:57.579 --> 00:48:59.060
passed by reference do they you just

1108
00:48:59.260 --> 00:49:00.409
don't have to put the star and it does

1109
00:49:00.608 --> 00:49:01.010
it for you

1110
00:49:01.210 --> 00:49:03.409
so there's they're definitely map is

1111
00:49:03.608 --> 00:49:05.930
special you cannot define map in the

1112
00:49:06.130 --> 00:49:07.700
language it's it has to be built in

1113
00:49:07.900 --> 00:49:09.230
because there's some curious things

1114
00:49:09.429 --> 00:49:15.619
about it okay good okay so we fetch the

1115
00:49:15.818 --> 00:49:18.649
page now we want to fire off a crawl go

1116
00:49:18.849 --> 00:49:20.599
routine for each URL mentioned in the

1117
00:49:20.798 --> 00:49:22.970
page we just fetch so that's done in

1118
00:49:23.170 --> 00:49:26.240
line 56 on line 50 sisters loops over

1119
00:49:26.440 --> 00:49:29.690
the URLs that the fetch function

1120
00:49:29.889 --> 00:49:32.750
returned and for each one fires off a go

1121
00:49:32.949 --> 00:49:35.539
routine at line 58 and that lines that

1122
00:49:35.739 --> 00:49:41.330
func syntax in line 58 is a closure or a

1123
00:49:41.530 --> 00:49:43.789
sort of immediate function but that func

1124
00:49:43.989 --> 00:49:46.399
thing keyword is doing is to clearing a

1125
00:49:46.599 --> 00:49:48.940
function right there that we then call

1126
00:49:49.139 --> 00:49:53.279
so the way to read it maybe is

1127
00:49:53.739 --> 00:49:56.580
that if you can declare a function as a

1128
00:49:56.780 --> 00:50:00.030
piece of data as just func you know and

1129
00:50:00.230 --> 00:50:03.149
then you give the arguments and then you

1130
00:50:03.349 --> 00:50:08.730
give the body and that's a clears and so

1131
00:50:08.929 --> 00:50:12.300
this is an object now this is like it's

1132
00:50:12.500 --> 00:50:13.800
like when you type one when you have a

1133
00:50:14.000 --> 00:50:18.149
one or 23 or something you're declaring

1134
00:50:18.349 --> 00:50:19.619
a sort of constant object and this is

1135
00:50:19.818 --> 00:50:20.879
the way to define a constant function

1136
00:50:21.079 --> 00:50:23.879
and we do it here because we want to

1137
00:50:24.079 --> 00:50:25.530
launch a go routine that's gonna run

1138
00:50:25.730 --> 00:50:27.090
this function that we declared right

1139
00:50:27.289 --> 00:50:28.919
here and so we in order to make the go

1140
00:50:29.119 --> 00:50:30.869
routine we have to add a go in front to

1141
00:50:31.068 --> 00:50:32.940
say we want to go routine and then we

1142
00:50:33.139 --> 00:50:34.859
have to call the function because the go

1143
00:50:35.059 --> 00:50:37.320
syntax says the syntax of the go

1144
00:50:37.519 --> 00:50:38.940
keywords as you follow it by a function

1145
00:50:39.139 --> 00:50:40.710
name and arguments you want to pass that

1146
00:50:40.909 --> 00:50:43.260
function and so we're gonna pass some

1147
00:50:43.460 --> 00:50:50.700
arguments here and there's two reasons

1148
00:50:50.900 --> 00:50:52.470
we're doing this well really this one

1149
00:50:52.670 --> 00:50:54.869
reason we you know in some other

1150
00:50:55.068 --> 00:50:57.590
circumstance we could have just said go

1151
00:50:57.789 --> 00:51:00.030
concurrent mutex oh I concur mutex is

1152
00:51:00.230 --> 00:51:01.200
the name of the function we actually

1153
00:51:01.400 --> 00:51:06.419
want to call with this URL but we want

1154
00:51:06.619 --> 00:51:07.919
to do a few other things as well so we

1155
00:51:08.119 --> 00:51:09.960
define this little helper function that

1156
00:51:10.159 --> 00:51:11.970
first calls concurrent mutex for us with

1157
00:51:12.170 --> 00:51:15.539
the URL and then after them current

1158
00:51:15.739 --> 00:51:16.919
mutex is finished we do something

1159
00:51:17.119 --> 00:51:19.320
special in order to help us wait for all

1160
00:51:19.519 --> 00:51:21.869
the crawls to be done before the outer

1161
00:51:22.068 --> 00:51:24.720
function returns so that brings us to

1162
00:51:24.920 --> 00:51:27.180
the the weight group the weight group at

1163
00:51:27.380 --> 00:51:29.369
line 55 it's a just a data structure to

1164
00:51:29.568 --> 00:51:33.419
find by go to help with coordination and

1165
00:51:33.619 --> 00:51:34.830
the game with weight group is that

1166
00:51:35.030 --> 00:51:39.090
internally it has a counter and you call

1167
00:51:39.289 --> 00:51:43.440
weight group dot add like a line 57 to

1168
00:51:43.639 --> 00:51:46.349
increment the counter and we group done

1169
00:51:46.548 --> 00:51:48.419
to decrement it and then this weight

1170
00:51:48.619 --> 00:51:50.700
what this weight method called line 63

1171
00:51:50.900 --> 00:51:52.919
waits for the counter to get down to

1172
00:51:53.119 --> 00:51:56.310
zero so a weight group is a way to wait

1173
00:51:56.510 --> 00:51:59.129
for a specific number of things to

1174
00:51:59.329 --> 00:52:02.340
finish and it's useful in a bunch of

1175
00:52:02.539 --> 00:52:03.810
different situations here we're using it

1176
00:52:04.010 --> 00:52:05.159
to wait for the last go routine to

1177
00:52:05.358 --> 00:52:05.720
finish

1178
00:52:05.920 --> 00:52:07.639
because we add one to the weight group

1179
00:52:07.838 --> 00:52:11.000
for every go routine we create line 60

1180
00:52:11.199 --> 00:52:12.919
at the end of this function we've

1181
00:52:13.119 --> 00:52:15.110
declared decrement the counter in the

1182
00:52:15.309 --> 00:52:17.930
weight group and then line three weights

1183
00:52:18.130 --> 00:52:20.050
until all the decrements have finished

1184
00:52:20.250 --> 00:52:22.100
and so the reason why we declared this

1185
00:52:22.300 --> 00:52:23.720
little function was basically to be able

1186
00:52:23.920 --> 00:52:26.330
to both call concurrently text and call

1187
00:52:26.530 --> 00:52:28.430
dot that's really why we needed that

1188
00:52:28.630 --> 00:52:39.560
function so the question is what if one

1189
00:52:39.760 --> 00:52:43.039
of the subroutines fails and doesn't

1190
00:52:43.239 --> 00:52:45.620
reach the done line that's a darn good

1191
00:52:45.820 --> 00:52:49.010
question there is you know if I forget

1192
00:52:49.210 --> 00:52:50.870
the exact range of errors that will

1193
00:52:51.070 --> 00:52:53.240
cause the go routine to fail without

1194
00:52:53.440 --> 00:52:54.950
causing the program to feel maybe

1195
00:52:55.150 --> 00:52:56.389
divides by zero I don't know where

1196
00:52:56.588 --> 00:52:57.590
dereference is a nil pointer

1197
00:52:57.789 --> 00:52:58.940
not sure but there are certainly ways

1198
00:52:59.139 --> 00:53:04.370
for a function to fail and I have the go

1199
00:53:04.570 --> 00:53:06.710
routine die without having the program

1200
00:53:06.909 --> 00:53:08.690
die and that would be a problem for us

1201
00:53:08.889 --> 00:53:11.930
and so really the white right way to I'm

1202
00:53:12.130 --> 00:53:13.460
sure you had this in mind and asking the

1203
00:53:13.659 --> 00:53:15.649
question the right way to write this to

1204
00:53:15.849 --> 00:53:18.320
be sure that the done call is made no

1205
00:53:18.519 --> 00:53:20.539
matter why this guru team is finishing

1206
00:53:20.739 --> 00:53:26.980
would be to put a defer here which means

1207
00:53:27.179 --> 00:53:31.340
call done before the surrounding

1208
00:53:31.539 --> 00:53:34.130
function finishes and always call it no

1209
00:53:34.329 --> 00:53:35.930
matter why the surrounding function is

1210
00:53:36.130 --> 00:53:42.119
finished yes

1211
00:53:53.559 --> 00:53:58.589
and yes yeah so the question is how come

1212
00:53:58.789 --> 00:54:00.450
two users have done in different threads

1213
00:54:00.650 --> 00:54:08.010
aren't a race yeah so the answer must be

1214
00:54:08.210 --> 00:54:10.440
that internally dot a weight group has a

1215
00:54:10.639 --> 00:54:13.970
mutex or something like it that each of

1216
00:54:14.170 --> 00:54:18.000
Dunn's methods acquires before doing

1217
00:54:18.199 --> 00:54:19.769
anything else so that simultaneously

1218
00:54:19.969 --> 00:54:22.589
calls to a done to await groups methods

1219
00:54:22.789 --> 00:54:32.170
are trees we could to did a low class

1220
00:54:39.518 --> 00:54:43.680
yeah for certain leaf C++ and in C you

1221
00:54:43.880 --> 00:54:45.240
want to look at something called P

1222
00:54:45.440 --> 00:54:47.190
threads for C threads come in a library

1223
00:54:47.389 --> 00:54:48.450
they're not really part of the language

1224
00:54:48.650 --> 00:54:51.510
called P threads which they have these

1225
00:54:51.710 --> 00:54:55.220
are extremely traditional and ancient

1226
00:54:55.420 --> 00:55:04.450
primitives that all languages yeah

1227
00:55:06.630 --> 00:55:12.019
say it again you know not in this code

1228
00:55:12.219 --> 00:55:13.940
but you know you could imagine a use of

1229
00:55:14.139 --> 00:55:15.050
weight groups I mean weight groups just

1230
00:55:15.250 --> 00:55:21.050
count stuff and yeah yeah yeah weight

1231
00:55:21.250 --> 00:55:22.789
group doesn't really care what you're

1232
00:55:22.989 --> 00:55:27.170
pounding or why I mean you know this is

1233
00:55:27.369 --> 00:55:45.650
the most common way to see it use you're

1234
00:55:45.849 --> 00:55:48.350
wondering why you is passed as a

1235
00:55:48.550 --> 00:55:54.580
parameter to the function at 58 okay

1236
00:55:54.780 --> 00:55:58.870
yeah this is alright so the question is

1237
00:55:59.070 --> 00:56:01.250
okay so actually backing up a little bit

1238
00:56:01.449 --> 00:56:05.690
the rules for these for a function like

1239
00:56:05.889 --> 00:56:08.810
the one I'm defining on 58 is that if

1240
00:56:09.010 --> 00:56:10.760
the function body mentions a variable

1241
00:56:10.960 --> 00:56:13.850
that's declared in the outer function

1242
00:56:14.050 --> 00:56:17.269
but not shadowed then the the inner

1243
00:56:17.469 --> 00:56:18.800
functions use of that is the same

1244
00:56:19.000 --> 00:56:20.450
variable in the inner function as in the

1245
00:56:20.650 --> 00:56:22.880
outer function and so that's what's

1246
00:56:23.079 --> 00:56:26.180
happening with Fechter for example like

1247
00:56:26.380 --> 00:56:28.580
what is this variable here refer to what

1248
00:56:28.780 --> 00:56:30.050
does the Fechter variable refer to in

1249
00:56:30.250 --> 00:56:32.780
the inner function well it refers it's

1250
00:56:32.980 --> 00:56:35.090
the same variable as as the fetcher in

1251
00:56:35.289 --> 00:56:37.280
the outer function says just is that

1252
00:56:37.480 --> 00:56:38.720
variable and so when the inner function

1253
00:56:38.920 --> 00:56:40.310
refers to fetcher it just means it's

1254
00:56:40.510 --> 00:56:42.110
just referring the same variable as this

1255
00:56:42.309 --> 00:56:45.470
one here and the same with F f is it's

1256
00:56:45.670 --> 00:56:47.960
used here it's just is this variable so

1257
00:56:48.159 --> 00:56:50.120
you might think that we could get rid of

1258
00:56:50.320 --> 00:56:55.789
the this u argument that we're passing

1259
00:56:55.989 --> 00:56:57.680
and just have the inner function take no

1260
00:56:57.880 --> 00:56:59.660
arguments at all but just use the U that

1261
00:56:59.860 --> 00:57:04.530
was defined up on line 56 in the loop

1262
00:57:05.070 --> 00:57:07.190
and it'll be nice if we could do that

1263
00:57:07.389 --> 00:57:09.710
because save us some typing it turns out

1264
00:57:09.909 --> 00:57:12.350
not to work and the reason is that the

1265
00:57:12.550 --> 00:57:15.860
semantics of go of the for loop at line

1266
00:57:16.059 --> 00:57:17.210
56 is that the

1267
00:57:17.409 --> 00:57:21.650
for the updates the variable you so in

1268
00:57:21.849 --> 00:57:23.420
the first iteration of the for loop that

1269
00:57:23.619 --> 00:57:29.180
variable u contains some URL and when

1270
00:57:29.380 --> 00:57:31.310
you enter the second iteration before

1271
00:57:31.510 --> 00:57:33.950
the that variable this contents are

1272
00:57:34.150 --> 00:57:37.550
changed to be the second URL and that

1273
00:57:37.750 --> 00:57:39.170
means that the first go routine that we

1274
00:57:39.369 --> 00:57:41.330
launched that's just looking at the

1275
00:57:41.530 --> 00:57:42.800
outer if it we're looking at the outer

1276
00:57:43.000 --> 00:57:46.730
functions u variable the that first go

1277
00:57:46.929 --> 00:57:48.710
team we launched would see a different

1278
00:57:48.909 --> 00:57:51.200
value in the u variable after the outer

1279
00:57:51.400 --> 00:57:53.600
function it updated it and sometimes

1280
00:57:53.800 --> 00:57:54.950
that's actually what you want so for

1281
00:57:55.150 --> 00:57:57.800
example for for F and then particular F

1282
00:57:58.000 --> 00:58:01.400
dot fetched we interaction absolutely

1283
00:58:01.599 --> 00:58:04.760
wants to see changes to that map but for

1284
00:58:04.960 --> 00:58:06.289
you we don't want to see changes the

1285
00:58:06.489 --> 00:58:08.870
first go routine we spawn should read

1286
00:58:09.070 --> 00:58:11.930
the first URL not the second URL so we

1287
00:58:12.130 --> 00:58:13.610
want that go routine to have a copy you

1288
00:58:13.809 --> 00:58:15.880
have its own private copy of the URL and

1289
00:58:16.079 --> 00:58:18.170
you know is we could have done it in

1290
00:58:18.369 --> 00:58:20.360
other ways we could have but the way

1291
00:58:20.559 --> 00:58:21.950
this code happens to do it to produce

1292
00:58:22.150 --> 00:58:25.430
the copy private to that inner function

1293
00:58:25.630 --> 00:58:31.860
is by passing the URLs in argument yes

1294
00:58:34.449 --> 00:58:36.690
yeah if we have passed the address of

1295
00:58:36.889 --> 00:58:51.000
you yeah then it uh it's actually I

1296
00:58:51.199 --> 00:58:51.990
don't know how strings work but it is

1297
00:58:52.190 --> 00:58:53.849
absolutely giving you your own private

1298
00:58:54.048 --> 00:58:59.940
copy of the variable you get your own

1299
00:59:00.139 --> 00:59:08.949
copy of the variable and it yeah

1300
00:59:26.500 --> 00:59:28.650
are you saying we don't need to play

1301
00:59:28.849 --> 00:59:33.660
this trick in the code we definitely

1302
00:59:33.860 --> 00:59:35.070
need to play this trick in the code and

1303
00:59:35.269 --> 00:59:37.500
what's going on is this it's so the

1304
00:59:37.699 --> 00:59:38.970
question is Oh strings are immutable

1305
00:59:39.170 --> 00:59:41.760
strings are immutable right yeah so how

1306
00:59:41.960 --> 00:59:43.650
kind of strings are immutable how can

1307
00:59:43.849 --> 00:59:44.910
the outer function change the string

1308
00:59:45.110 --> 00:59:47.519
there should be no problem the problem

1309
00:59:47.719 --> 00:59:49.500
is not that the string is changed the

1310
00:59:49.699 --> 00:59:51.300
problem is that the variable U is

1311
00:59:51.500 --> 00:59:55.950
changed so the when the inner function

1312
00:59:56.150 --> 00:59:57.660
mentions a variable that's defined in

1313
00:59:57.860 --> 00:59:58.800
the outer function it's referring to

1314
00:59:59.000 --> 01:00:00.870
that variable and the variables current

1315
01:00:01.070 --> 01:00:03.120
value so when you if you have a string

1316
01:00:03.320 --> 01:00:06.390
variable that has has a in it and then

1317
01:00:06.590 --> 01:00:08.910
you assign B to that string variable

1318
01:00:09.110 --> 01:00:10.320
you're not over writing the string

1319
01:00:10.519 --> 01:00:12.330
you're changing the variable to point to

1320
01:00:12.530 --> 01:00:15.750
a different string and and because the

1321
01:00:15.949 --> 01:00:18.480
for loop changes the U variable to point

1322
01:00:18.679 --> 01:00:21.090
to a different string you know that

1323
01:00:21.289 --> 01:00:22.769
change to you would be visible inside

1324
01:00:22.969 --> 01:00:24.480
the inner function and therefore the

1325
01:00:24.679 --> 01:00:26.190
inner function needs its own copy of the

1326
01:00:26.389 --> 01:00:29.259
variable

1327
01:00:36.150 --> 01:00:42.000
essentially make a copy of that so that

1328
01:00:50.250 --> 01:00:52.910
okay but that is what we're doing in

1329
01:00:53.110 --> 01:00:54.470
this code and that's that is why this

1330
01:00:54.670 --> 01:00:56.240
code works okay

1331
01:00:56.440 --> 01:00:58.880
the proposal or the broken code that

1332
01:00:59.079 --> 01:01:00.200
we're not using here I will show you the

1333
01:01:00.400 --> 01:01:02.849
broken code

1334
01:01:44.059 --> 01:01:46.240
this is just like a horrible detail but

1335
01:01:46.440 --> 01:01:47.500
it is unfortunately one that you'll run

1336
01:01:47.699 --> 01:01:50.650
into while doing the labs so you should

1337
01:01:50.849 --> 01:01:52.000
be at least where that there's a problem

1338
01:01:52.199 --> 01:01:54.490
and when you run into it maybe you can

1339
01:01:54.690 --> 01:02:11.970
try to figure out the details okay

1340
01:02:12.170 --> 01:02:15.670
that's a great question so so the

1341
01:02:15.869 --> 01:02:17.890
question is you know if you have an

1342
01:02:18.090 --> 01:02:19.570
inner function just a repeated if you

1343
01:02:19.769 --> 01:02:20.980
have an inner function that refers to a

1344
01:02:21.179 --> 01:02:23.230
variable in the surrounding function but

1345
01:02:23.429 --> 01:02:25.780
the surrounding function returns what is

1346
01:02:25.980 --> 01:02:28.390
the inner functions variable referring

1347
01:02:28.590 --> 01:02:29.830
to anymore since the outer function is

1348
01:02:30.030 --> 01:02:32.260
as returned and the answer is that go

1349
01:02:32.460 --> 01:02:34.990
notices go analyzes your inner functions

1350
01:02:35.190 --> 01:02:37.960
or these are called closures go analyzes

1351
01:02:38.159 --> 01:02:39.670
them the compiler analyze them says aha

1352
01:02:39.869 --> 01:02:41.380
oh this disclosure this inner function

1353
01:02:41.579 --> 01:02:42.370
is using a variable in the outer

1354
01:02:42.570 --> 01:02:44.110
function we're actually gonna and the

1355
01:02:44.309 --> 01:02:47.380
compiler will allocate heat memory to

1356
01:02:47.579 --> 01:02:50.470
hold the variable the you know the

1357
01:02:50.670 --> 01:02:52.390
current value of the variable and both

1358
01:02:52.590 --> 01:02:55.030
functions will refer to that that little

1359
01:02:55.230 --> 01:02:58.150
area heap that has the barrel so it

1360
01:02:58.349 --> 01:02:59.560
won't be allocated the variable won't be

1361
01:02:59.760 --> 01:03:01.390
on the stack as you might expect it's

1362
01:03:01.590 --> 01:03:02.980
moved to the heap if if the compiler

1363
01:03:03.179 --> 01:03:04.780
sees that it's using a closure and then

1364
01:03:04.980 --> 01:03:05.860
when the outer function returns the

1365
01:03:06.059 --> 01:03:07.750
object is still there in the heap the

1366
01:03:07.949 --> 01:03:09.640
inner function can still get at it and

1367
01:03:09.840 --> 01:03:11.620
then the garbage collector is

1368
01:03:11.820 --> 01:03:13.240
responsible for noticing that the last

1369
01:03:13.440 --> 01:03:15.340
function to refer to this little piece

1370
01:03:15.539 --> 01:03:18.340
of heat that's exited returned and to

1371
01:03:18.539 --> 01:03:24.568
free it only then okay okay

1372
01:03:24.768 --> 01:03:29.109
okay so wait group wait group is maybe

1373
01:03:29.309 --> 01:03:30.429
the more important thing here that the

1374
01:03:30.628 --> 01:03:32.349
technique that this code uses to wait

1375
01:03:32.548 --> 01:03:35.519
for all the all this level of crawls to

1376
01:03:35.719 --> 01:03:37.539
finished all its direct chill and the

1377
01:03:37.739 --> 01:03:39.399
finish is the wait group of course

1378
01:03:39.599 --> 01:03:41.079
there's many of these wait groups one

1379
01:03:41.278 --> 01:03:44.709
per call two concurrent mutex each call

1380
01:03:44.909 --> 01:03:46.089
that concurrent mutex just waits for its

1381
01:03:46.289 --> 01:03:49.318
own children to finish and then returns

1382
01:03:49.518 --> 01:03:53.409
okay so back to the lock actually

1383
01:03:53.608 --> 01:03:54.278
there's one more thing I want to talk

1384
01:03:54.478 --> 01:03:56.079
about with a lock and that is to explore

1385
01:03:56.278 --> 01:03:57.749
what would happen if we hadn't locked

1386
01:03:57.949 --> 01:04:00.489
right I'm claiming oh you know you don't

1387
01:04:00.688 --> 01:04:02.169
lock you're gonna get these races you're

1388
01:04:02.369 --> 01:04:05.009
gonna get incorrect execution whatever

1389
01:04:05.208 --> 01:04:10.839
let's give it a shot I'm gonna I'm gonna

1390
01:04:11.039 --> 01:04:14.318
comment out the locks and the question

1391
01:04:14.518 --> 01:04:16.959
is what happens if I run the code with

1392
01:04:17.159 --> 01:04:23.979
no locks what am I gonna see so we may

1393
01:04:24.179 --> 01:04:26.259
see a ru or I'll call twice or I fetch

1394
01:04:26.458 --> 01:04:28.389
twice yeah that's yeah that would be the

1395
01:04:28.588 --> 01:04:31.449
error you might expect alright so I'll

1396
01:04:31.648 --> 01:04:34.599
run it without locks and we're looking

1397
01:04:34.798 --> 01:04:36.068
at the concurrent map the one in the

1398
01:04:36.268 --> 01:04:38.259
middle this time it doesn't seem to have

1399
01:04:38.458 --> 01:04:40.169
fetched anything twice it's only five

1400
01:04:40.369 --> 01:04:48.939
run again gosh so far genius so maybe

1401
01:04:49.139 --> 01:04:50.519
we're wasting our time with those locks

1402
01:04:50.719 --> 01:04:52.298
yeah never seems to go wrong I've

1403
01:04:52.498 --> 01:04:57.219
actually never seem to go wrong so the

1404
01:04:57.418 --> 01:05:00.068
code is nevertheless wrong and someday

1405
01:05:00.268 --> 01:05:03.129
it will fail okay the problem is that

1406
01:05:03.329 --> 01:05:04.359
you know this is only a couple of

1407
01:05:04.559 --> 01:05:05.979
instructions here and so the chances of

1408
01:05:06.179 --> 01:05:07.778
these two threads which are maybe

1409
01:05:07.978 --> 01:05:09.339
hundreds of instructions happening to

1410
01:05:09.539 --> 01:05:12.068
stumble on this you know the same couple

1411
01:05:12.268 --> 01:05:14.289
of instructions at the same time is

1412
01:05:14.489 --> 01:05:17.528
quite low and indeed and and this is a

1413
01:05:17.728 --> 01:05:20.259
real bummer about buggy code with races

1414
01:05:20.458 --> 01:05:23.318
is that it usually works just fine but

1415
01:05:23.518 --> 01:05:25.089
it probably won't work when the customer

1416
01:05:25.289 --> 01:05:27.820
runs it on their computer

1417
01:05:28.019 --> 01:05:30.310
so it's actually bad news for us right

1418
01:05:30.510 --> 01:05:32.740
what do we you know it it can be in

1419
01:05:32.940 --> 01:05:34.720
complex programs quite difficult to

1420
01:05:34.920 --> 01:05:36.970
figure out if you have a race right and

1421
01:05:37.170 --> 01:05:39.190
you might you may have code that just

1422
01:05:39.389 --> 01:05:41.710
looks completely reasonable that is in

1423
01:05:41.909 --> 01:05:44.410
fact sort of unknown to you using shared

1424
01:05:44.610 --> 01:05:47.769
variables and the answer is you really

1425
01:05:47.969 --> 01:05:49.840
the only way to find races in practice

1426
01:05:50.039 --> 01:05:53.380
to be is you automated tools and luckily

1427
01:05:53.579 --> 01:05:55.690
go actually gives us this pretty good

1428
01:05:55.889 --> 01:05:59.919
race detector built-in to go and you

1429
01:06:00.119 --> 01:06:04.419
should use it so if you pass the - race

1430
01:06:04.619 --> 01:06:06.340
flag when you have to get your go

1431
01:06:06.539 --> 01:06:09.510
program and run this race detector which

1432
01:06:09.710 --> 01:06:11.560
well I'll run the race detector and

1433
01:06:11.760 --> 01:06:16.450
we'll see so it emits an error message

1434
01:06:16.650 --> 01:06:19.480
from us it's found a race and it

1435
01:06:19.679 --> 01:06:21.220
actually tells us exactly where the race

1436
01:06:21.420 --> 01:06:23.350
happened so there's a lot of junk in

1437
01:06:23.550 --> 01:06:25.060
this output but the really critical

1438
01:06:25.260 --> 01:06:28.120
thing is that the race detector realize

1439
01:06:28.320 --> 01:06:29.980
that we had read a variable that's what

1440
01:06:30.179 --> 01:06:32.590
this read is that was previously written

1441
01:06:32.789 --> 01:06:35.470
and there was no intervening release and

1442
01:06:35.670 --> 01:06:37.570
acquire of a lock that's what that's

1443
01:06:37.769 --> 01:06:40.000
what this means furthermore it tells us

1444
01:06:40.199 --> 01:06:43.510
the line number so it's told us that the

1445
01:06:43.710 --> 01:06:49.090
read was a line 43 and the write the

1446
01:06:49.289 --> 01:06:51.460
previous write was at line 44 and indeed

1447
01:06:51.659 --> 01:06:52.990
we look at the code and the read isn't

1448
01:06:53.190 --> 01:06:56.019
line 43 and the right is at lying 44 so

1449
01:06:56.219 --> 01:06:57.970
that means that one thread did a write

1450
01:06:58.170 --> 01:07:00.669
at line 44 and then without any

1451
01:07:00.869 --> 01:07:02.320
intervening lock and another thread came

1452
01:07:02.519 --> 01:07:05.140
along and read that written data at line

1453
01:07:05.340 --> 01:07:07.360
43 that's basically what the race

1454
01:07:07.559 --> 01:07:09.820
detector is looking for the way it works

1455
01:07:10.019 --> 01:07:11.620
internally is it allocates sort of

1456
01:07:11.820 --> 01:07:14.800
shadow memory now lucky some you know it

1457
01:07:15.000 --> 01:07:16.060
uses a huge amount of memory and

1458
01:07:16.260 --> 01:07:17.260
basically for every one of your memory

1459
01:07:17.460 --> 01:07:19.510
locations the race detector is allocated

1460
01:07:19.710 --> 01:07:21.400
a little bit of memory itself in which

1461
01:07:21.599 --> 01:07:24.130
it keeps track of which threads recently

1462
01:07:24.329 --> 01:07:26.200
read or wrote every single memory

1463
01:07:26.400 --> 01:07:28.390
location and then when and it also to

1464
01:07:28.590 --> 01:07:30.610
keep tracking keeping track of when

1465
01:07:30.809 --> 01:07:32.409
threads acquiring release locks and do

1466
01:07:32.608 --> 01:07:35.230
other synchronization activities that it

1467
01:07:35.429 --> 01:07:37.780
knows forces but force threads to not

1468
01:07:37.980 --> 01:07:38.980
run

1469
01:07:39.179 --> 01:07:40.780
and if the race detector driver sees a

1470
01:07:40.980 --> 01:07:42.250
ha there was a memory location that was

1471
01:07:42.449 --> 01:07:45.010
written and then read with no

1472
01:07:45.210 --> 01:07:48.960
intervening market it'll raise an error

1473
01:07:49.159 --> 01:08:06.400
yes I believe it is not perfect yeah I

1474
01:08:06.599 --> 01:08:11.970
have to think about it what one

1475
01:08:12.170 --> 01:08:14.980
certainly one way it is not perfect is

1476
01:08:15.179 --> 01:08:18.699
that if you if you don't execute some

1477
01:08:18.899 --> 01:08:21.070
code the race detector doesn't know

1478
01:08:21.270 --> 01:08:24.909
anything about it so it's not analyzing

1479
01:08:25.109 --> 01:08:27.789
it's not doing static analysis the

1480
01:08:27.989 --> 01:08:29.020
racing sectors not looking at your

1481
01:08:29.220 --> 01:08:31.570
source and making decisions based on the

1482
01:08:31.770 --> 01:08:33.190
source it's sort of watching what

1483
01:08:33.390 --> 01:08:35.500
happened at on this particular run of

1484
01:08:35.699 --> 01:08:37.449
the program and so if this particular

1485
01:08:37.649 --> 01:08:39.130
run of the program didn't execute some

1486
01:08:39.329 --> 01:08:42.250
code that happens to read or write

1487
01:08:42.449 --> 01:08:44.170
shared data then the race detector will

1488
01:08:44.369 --> 01:08:46.300
never know and there could be erased

1489
01:08:46.500 --> 01:08:48.070
there so that's certainly something to

1490
01:08:48.270 --> 01:08:49.119
watch out for so you know if you're

1491
01:08:49.319 --> 01:08:50.380
serious about the race detector you need

1492
01:08:50.579 --> 01:08:52.900
to set up sort of testing apparatus that

1493
01:08:53.100 --> 01:08:55.420
tries to make sure all all the code is

1494
01:08:55.619 --> 01:08:59.140
executed but it's it's it's very good

1495
01:08:59.340 --> 01:09:01.420
and you just have to use it for your 8

1496
01:09:01.619 --> 01:09:07.630
to 4 lives okay so this is race here and

1497
01:09:07.829 --> 01:09:09.100
of course the race didn't actually occur

1498
01:09:09.300 --> 01:09:12.130
what the race editor did not see was the

1499
01:09:12.329 --> 01:09:14.170
actual interleaving simultaneous

1500
01:09:14.369 --> 01:09:17.170
execution of some sensitive code right

1501
01:09:17.369 --> 01:09:18.699
it didn't see two threads literally

1502
01:09:18.899 --> 01:09:21.659
execute lines 43 and 44 at the same time

1503
01:09:21.859 --> 01:09:23.770
and as we know from having run the

1504
01:09:23.970 --> 01:09:24.940
things by hand that apparently doesn't

1505
01:09:25.140 --> 01:09:28.119
happen only with low probability all it

1506
01:09:28.319 --> 01:09:29.680
saw was at one point that was a right

1507
01:09:29.880 --> 01:09:31.329
and they made me much later there was a

1508
01:09:31.529 --> 01:09:37.420
read with no intervening walk and so

1509
01:09:37.619 --> 01:09:38.980
enact in that sense it can sort of

1510
01:09:39.180 --> 01:09:41.340
detect races that didn't actually happen

1511
01:09:41.539 --> 01:09:47.630
or didn't really cause bugs okay

1512
01:09:49.539 --> 01:09:52.350
okay one final question about this this

1513
01:09:52.550 --> 01:09:57.550
crawler how many threads does it create

1514
01:10:03.639 --> 01:10:09.918
yeah and how many concurrent threads

1515
01:10:10.118 --> 01:10:24.769
could there be yeah so a defect in this

1516
01:10:24.969 --> 01:10:26.958
crawler is that there's no obvious bound

1517
01:10:27.158 --> 01:10:28.519
on the number of simultaneous threads

1518
01:10:28.719 --> 01:10:30.380
that might create you know with the test

1519
01:10:30.579 --> 01:10:32.600
case which only has five URLs big

1520
01:10:32.800 --> 01:10:34.458
whoopee but if you're crawling a real

1521
01:10:34.658 --> 01:10:36.409
wheel web with you know I don't know are

1522
01:10:36.609 --> 01:10:38.180
there billions of URLs out there maybe

1523
01:10:38.380 --> 01:10:40.189
not we certainly don't want to be in a

1524
01:10:40.389 --> 01:10:41.180
position where the crawler might

1525
01:10:41.380 --> 01:10:43.180
accidentally create billions of threads

1526
01:10:43.380 --> 01:10:45.918
because you know thousands of threads

1527
01:10:46.118 --> 01:10:47.689
it's just fine billions of threads it's

1528
01:10:47.889 --> 01:10:50.869
not okay because each one sits on some

1529
01:10:51.069 --> 01:10:54.079
amount of memory so a you know there's

1530
01:10:54.279 --> 01:10:55.880
probably many defects in real life for

1531
01:10:56.079 --> 01:10:58.070
this crawler but one at the level we're

1532
01:10:58.270 --> 01:11:00.019
talking about is that it does create too

1533
01:11:00.219 --> 01:11:01.400
many threads and really ought to have a

1534
01:11:01.600 --> 01:11:03.079
way of saying well you can create 20

1535
01:11:03.279 --> 01:11:04.430
threads or 100 threads or a thousand

1536
01:11:04.630 --> 01:11:06.320
threads but no more so one way to do

1537
01:11:06.520 --> 01:11:07.998
that would be to pre create a pool a

1538
01:11:08.198 --> 01:11:10.850
fixed size pool of workers and have the

1539
01:11:11.050 --> 01:11:12.979
workers just iteratively look for

1540
01:11:13.179 --> 01:11:14.630
another URL to crawl crawl that URL

1541
01:11:14.829 --> 01:11:17.958
rather than creating a new thread for

1542
01:11:18.158 --> 01:11:20.869
each URL okay so next up I want to talk

1543
01:11:21.069 --> 01:11:23.029
about a another crawler that's

1544
01:11:23.229 --> 01:11:25.400
implemented and a significantly

1545
01:11:25.600 --> 01:11:28.579
different way using channels instead of

1546
01:11:28.779 --> 01:11:31.668
shared memory it's a member on the mutex

1547
01:11:31.868 --> 01:11:33.288
call or I just said there is this table

1548
01:11:33.488 --> 01:11:34.640
of URLs that are called that's shared

1549
01:11:34.840 --> 01:11:36.350
between all the threads and asked me

1550
01:11:36.550 --> 01:11:40.130
locked this version does not have such a

1551
01:11:40.329 --> 01:11:44.239
table does not share memory and does not

1552
01:11:44.439 --> 01:11:52.310
need to use locks okay so this one the

1553
01:11:52.510 --> 01:11:54.860
instead there's basically a master

1554
01:11:55.060 --> 01:11:57.590
thread that's his master function on a

1555
01:11:57.789 --> 01:12:00.498
decent 986 and it has a table but the

1556
01:12:00.698 --> 01:12:02.600
table is private to the master function

1557
01:12:02.800 --> 01:12:06.489
and what the master function is doing is

1558
01:12:06.689 --> 01:12:09.019
instead of sort of basically creating a

1559
01:12:09.219 --> 01:12:11.208
tree of functions that corresponds to

1560
01:12:11.408 --> 01:12:13.130
the exploration of the graph which the

1561
01:12:13.329 --> 01:12:17.739
previous crawler did this one fires off

1562
01:12:17.939 --> 01:12:21.680
one ute one guru team per URL that it's

1563
01:12:21.880 --> 01:12:23.570
fetches and that but it's only the

1564
01:12:23.770 --> 01:12:26.360
master only the one master that's

1565
01:12:26.560 --> 01:12:28.100
creating these threads so we don't have

1566
01:12:28.300 --> 01:12:29.930
a tree of functions creating threads we

1567
01:12:30.130 --> 01:12:34.998
just have the one master okay so it

1568
01:12:35.198 --> 01:12:37.340
creates its own private map a line 88

1569
01:12:37.539 --> 01:12:41.350
this record what it's fetched and then

1570
01:12:41.550 --> 01:12:44.449
it also creates a channel just a single

1571
01:12:44.649 --> 01:12:46.699
channel that all of its worker threads

1572
01:12:46.899 --> 01:12:48.920
are going to talk to and the idea is

1573
01:12:49.119 --> 01:12:50.498
that it's gonna fire up a worker thread

1574
01:12:50.698 --> 01:12:52.840
and each worker thread that it fires up

1575
01:12:53.039 --> 01:12:55.430
when it finished such as fetching the

1576
01:12:55.630 --> 01:12:57.949
page will send exactly one item back to

1577
01:12:58.149 --> 01:13:00.050
the master on the channel and that item

1578
01:13:00.250 --> 01:13:03.019
will be a list of the URLs in the page

1579
01:13:03.219 --> 01:13:07.760
that that worker thread fetched so the

1580
01:13:07.960 --> 01:13:10.220
master sits in a loop we're in line

1581
01:13:10.420 --> 01:13:13.788
eighty nine is reading entries from the

1582
01:13:13.988 --> 01:13:16.579
channel and so we have to imagine that

1583
01:13:16.779 --> 01:13:20.269
it's started up some workers in advance

1584
01:13:20.469 --> 01:13:22.640
and now it's reading the information the

1585
01:13:22.840 --> 01:13:24.288
URL lists that those workers send back

1586
01:13:24.488 --> 01:13:26.630
and each time he gets a URL is sitting

1587
01:13:26.829 --> 01:13:28.610
on land eighty nine it then loops over

1588
01:13:28.810 --> 01:13:32.420
the URLs in that URL list from a single

1589
01:13:32.619 --> 01:13:35.900
page fetch align ninety and if the URL

1590
01:13:36.100 --> 01:13:39.769
hasn't already been fetched it fires off

1591
01:13:39.969 --> 01:13:41.989
a new worker at line 94 to fetch that

1592
01:13:42.189 --> 01:13:44.600
URL and if we look at the worker code

1593
01:13:44.800 --> 01:13:47.119
online starting line 77 basically calls

1594
01:13:47.319 --> 01:13:50.930
his fetcher and then sends a message on

1595
01:13:51.130 --> 01:13:53.510
the channel a line 80 or 82 saying

1596
01:13:53.710 --> 01:13:57.729
here's the URLs in the page they fetched

1597
01:13:57.929 --> 01:14:00.970
and notice that now that the maybe

1598
01:14:01.170 --> 01:14:03.439
interesting thing about this is that the

1599
01:14:03.639 --> 01:14:07.788
worker threads don't share any objects

1600
01:14:07.988 --> 01:14:10.010
there's no shared object between the

1601
01:14:10.210 --> 01:14:11.329
workers and the master so we don't have

1602
01:14:11.529 --> 01:14:12.650
to worry about locking we don't have to

1603
01:14:12.850 --> 01:14:16.159
worry about rhesus instead this is a

1604
01:14:16.359 --> 01:14:18.739
example of sort of communicating

1605
01:14:18.939 --> 01:14:20.900
information instead of getting at it

1606
01:14:21.100 --> 01:14:25.620
through shared memory yes

1607
01:14:33.930 --> 01:14:37.940
yeah yeah so the observation is that the

1608
01:14:38.140 --> 01:14:40.610
code appears but the workers are the

1609
01:14:40.810 --> 01:14:42.050
observation is the workers are modifying

1610
01:14:42.250 --> 01:14:47.130
ch while the Masters reading it and

1611
01:14:49.170 --> 01:14:51.320
that's not the way the go authors would

1612
01:14:51.520 --> 01:14:53.960
like you to think about this the way

1613
01:14:54.159 --> 01:14:55.159
they want you to think about this is

1614
01:14:55.359 --> 01:14:57.829
that CH is a channel and the channel has

1615
01:14:58.029 --> 01:15:00.680
send and receive operations and the

1616
01:15:00.880 --> 01:15:02.869
workers are sending on the channel while

1617
01:15:03.069 --> 01:15:05.060
the master receives on the channel and

1618
01:15:05.260 --> 01:15:09.050
that's perfectly legal the channel is

1619
01:15:09.250 --> 01:15:10.850
happy I mean what that really means is

1620
01:15:11.050 --> 01:15:12.590
that the internal implementation of

1621
01:15:12.789 --> 01:15:15.409
channel has a mutex in it and the

1622
01:15:15.609 --> 01:15:18.800
channel operations are careful to take

1623
01:15:19.000 --> 01:15:20.659
out the mutex when they're messing with

1624
01:15:20.859 --> 01:15:22.248
the channels internal data to ensure

1625
01:15:22.448 --> 01:15:23.989
that it doesn't actually have any

1626
01:15:24.189 --> 01:15:27.380
reasons in it but yeah channels are sort

1627
01:15:27.579 --> 01:15:29.090
of protected against concurrency and

1628
01:15:29.289 --> 01:15:30.199
you're allowed to use them concurrently

1629
01:15:30.399 --> 01:15:34.679
from different threads yes

1630
01:15:36.389 --> 01:15:43.190
over the channel receive yes

1631
01:15:53.810 --> 01:15:56.060
we don't need to close the channel I

1632
01:15:56.260 --> 01:15:58.650
mean okay the the break statement is

1633
01:15:58.850 --> 01:16:00.390
about when the crawl has completely

1634
01:16:00.590 --> 01:16:02.960
finished and we fetched every single URL

1635
01:16:03.159 --> 01:16:06.210
right because hey what's going on is the

1636
01:16:06.409 --> 01:16:09.029
master is keeping I mean this n value is

1637
01:16:09.229 --> 01:16:12.989
private value and a master every time it

1638
01:16:13.189 --> 01:16:14.659
fires off a worker at increments the end

1639
01:16:14.859 --> 01:16:17.159
though every worker it starts since

1640
01:16:17.359 --> 01:16:20.279
exactly one item on the channel and so

1641
01:16:20.479 --> 01:16:21.720
every time the master reads an item off

1642
01:16:21.920 --> 01:16:22.920
the channel it knows that one of his

1643
01:16:23.119 --> 01:16:24.720
workers is finished and when the number

1644
01:16:24.920 --> 01:16:28.860
of outstanding workers goes to zero then

1645
01:16:29.060 --> 01:16:32.670
we're done and we don't once the number

1646
01:16:32.869 --> 01:16:34.320
of outstanding workers goes to zero then

1647
01:16:34.520 --> 01:16:36.300
the only reference to the channel is

1648
01:16:36.500 --> 01:16:40.170
from the master or from oh really from

1649
01:16:40.369 --> 01:16:41.579
the code that calls the master and so

1650
01:16:41.779 --> 01:16:43.260
the garbage collector will very soon see

1651
01:16:43.460 --> 01:16:45.060
that the channel has no references to it

1652
01:16:45.260 --> 01:16:48.480
and will free the channel so in this

1653
01:16:48.680 --> 01:16:49.860
case sometimes you need to close

1654
01:16:50.060 --> 01:16:53.430
channels but actually I rarely have to

1655
01:16:53.630 --> 01:16:56.170
close channels

1656
01:17:03.149 --> 01:17:06.049
he said again

1657
01:17:09.748 --> 01:17:12.019
so the question is alright so you can

1658
01:17:12.219 --> 01:17:16.189
see at line 106 before calling master

1659
01:17:16.389 --> 01:17:19.748
concurrent channel sort of fires up one

1660
01:17:19.948 --> 01:17:25.458
shoves one URL into the channel and it's

1661
01:17:25.658 --> 01:17:26.510
to sort of get the whole thing started

1662
01:17:26.710 --> 01:17:27.859
because the code for master was written

1663
01:17:28.059 --> 01:17:29.269
you know the master goes right into

1664
01:17:29.469 --> 01:17:31.548
reading from the channel line 89 so

1665
01:17:31.748 --> 01:17:33.288
there better be something in the channel

1666
01:17:33.488 --> 01:17:36.350
otherwise line 89 would block forever so

1667
01:17:36.550 --> 01:17:38.060
if it weren't for that little code at

1668
01:17:38.260 --> 01:17:42.350
line 107 the for loop at 89 would block

1669
01:17:42.550 --> 01:17:43.850
reading from the channel forever and

1670
01:17:44.050 --> 01:17:54.260
this code wouldn't work well yeah so the

1671
01:17:54.460 --> 01:17:56.088
observation is gosh you know wouldn't it

1672
01:17:56.288 --> 01:17:57.310
be nice to be able to write code that

1673
01:17:57.510 --> 01:17:59.329
would be able to notice if there's

1674
01:17:59.529 --> 01:18:01.369
nothing waiting on the channel and you

1675
01:18:01.569 --> 01:18:03.019
can if you look up the Select statement

1676
01:18:03.219 --> 01:18:04.819
it's much more complicated than this but

1677
01:18:05.019 --> 01:18:06.378
there is the Select statement which

1678
01:18:06.578 --> 01:18:09.260
allows you to proceed to not block if

1679
01:18:09.460 --> 01:18:10.939
something if there's nothing waiting on

1680
01:18:11.139 --> 01:18:13.590
the channel

1681
01:18:44.590 --> 01:18:59.400
because the work resin finish okay sorry

1682
01:18:59.600 --> 01:19:02.400
to the first question is there I think

1683
01:19:02.600 --> 01:19:03.630
what you're really worried about is

1684
01:19:03.829 --> 01:19:05.430
whether we're actually able to launch

1685
01:19:05.630 --> 01:19:08.909
parallel so the very first step won't be

1686
01:19:09.109 --> 01:19:37.020
in parallel because there's an exit

1687
01:19:37.220 --> 01:19:40.070
owner the for-loop weights in at line 89

1688
01:19:40.270 --> 01:19:44.250
that's not okay that for loop at line 89

1689
01:19:44.449 --> 01:19:47.460
is does not just loop over the current

1690
01:19:47.659 --> 01:19:48.989
contents of the channel and then quit

1691
01:19:49.189 --> 01:19:54.029
that is the for loop at 89 is going to

1692
01:19:54.229 --> 01:19:57.900
read it may never exit but it's gonna

1693
01:19:58.100 --> 01:19:59.579
read it's just going to keep waiting

1694
01:19:59.779 --> 01:20:00.930
until something shows up in the channel

1695
01:20:01.130 --> 01:20:04.079
so if you don't hit the break at line 99

1696
01:20:04.279 --> 01:20:10.050
the for loop own exit yeah alright I'm

1697
01:20:10.250 --> 01:20:12.239
afraid we're out of time we'll continue

1698
01:20:12.439 --> 01:20:15.600
this actually we have a presentation

1699
01:20:15.800 --> 01:20:18.060
scheduled by the TAS which I'll talk

1700
01:20:18.260 --> 01:20:23.260
more about go

